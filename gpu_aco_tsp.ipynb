{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bonaiuti.sandro93@gmail.com",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoniobelotti/gpu_aco_tsp/blob/master/gpu_aco_tsp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcrTWUB87XmP",
        "outputId": "9081a61a-337c-4d82-d186-18cdf58f1753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep  5 09:49:17 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAXh_1Eq7rG8",
        "outputId": "5e402525-7433-430a-96cb-88b32aab31a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "cOwUP61S90V5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![immagine.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "APLOYaQBSoqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comment this to enable output\n",
        "%%capture \n",
        "\n",
        "# remove default colab stuff\n",
        "!rm -rf sample_data \n",
        "\n",
        "#create directory structure\n",
        "!mkdir -p src/lib/cuda\n",
        "!mkdir -p src/lib/sequential\n",
        "\n",
        "# download TSPLIB intsances\n",
        "!git clone https://github.com/mastqe/tsplib.git data\n",
        "\n",
        "# Install nvcc colab plugin\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter\n",
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "id": "U26pok5QVVlH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code"
      ],
      "metadata": {
        "id": "nO2j5EZ6XKSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sequential implementation"
      ],
      "metadata": {
        "id": "hfztUXOAXpew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Code to read TSPLIB instances\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yr4keply-C2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name lib/sequential/tsplib.h\n",
        "#ifndef TSPLIB_H\n",
        "#define TSPLIB_H\n",
        "\n",
        "#define ASCII_SLASH 47\n",
        "#define ASCII_0 48\n",
        "#define ASCII_9 57\n",
        "\n",
        "typedef struct node_t{\n",
        "    int id;\n",
        "    int x;\n",
        "    int y;\n",
        "} Node;\n",
        "\n",
        "typedef struct TSPInstance_t {\n",
        "    const int numOfNodes;\n",
        "    Node *nodes;\n",
        "    float *edgeCosts;\n",
        "} TSPInstance;\n",
        "\n",
        "\n",
        "TSPInstance tsp_instance_read(const char *filename);\n",
        "void tsp_instance_free(TSPInstance *instance);\n",
        "\n",
        "#endif //TSPLIB_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OjwZWOg0-MrC",
        "outputId": "90ea807c-6800-4bf1-dc69-f9466c312933"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/sequential/tsplib.h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name lib/sequential/tsplib.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include \"tsplib.h\"\n",
        "\n",
        "\n",
        "TSPInstance tsp_instance_read(const char *filename) {\n",
        "    printf(\"Reading tsplib instances from %s\\n\", filename);\n",
        "\n",
        "    FILE *f = fopen(filename, \"r\");\n",
        "    if (f == NULL) {\n",
        "        printf(\"Error reading file!\");\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "    unsigned long filename_len = strlen(filename);\n",
        "    const char *s = filename + filename_len; // pointer to last char\n",
        "    for (; *s != ASCII_SLASH; s--); // scan backwards until / is found\n",
        "    for (; *s < ASCII_0 || *s > ASCII_9; s++); // scan forward until a digit is found\n",
        "\n",
        "    int num_of_nodes = strtol(s, NULL, 10);\n",
        "\n",
        "    char line_buff[64];\n",
        "    Node *nodes = malloc(sizeof *nodes * num_of_nodes);\n",
        "\n",
        "    while (fgets(line_buff, sizeof line_buff, f) != NULL &&\n",
        "           strncmp(line_buff, \"NODE_COORD_SECTION\", strlen(\"NODE_COORD_SECTION\")) != 0);\n",
        "\n",
        "    while (fgets(line_buff, sizeof line_buff, f) != NULL && strncmp(line_buff, \"EOF\", 3) != 0) {\n",
        "\n",
        "        int progr, x, y;\n",
        "\n",
        "        char *buff_cursor;\n",
        "        progr = strtol(line_buff, &buff_cursor, 10);\n",
        "        x = strtol(buff_cursor, &buff_cursor, 10);\n",
        "        y = strtol(buff_cursor, &buff_cursor, 10);\n",
        "\n",
        "        // convert to 0-indexed\n",
        "        progr -= 1;\n",
        "\n",
        "        nodes[progr].id = progr;\n",
        "        nodes[progr].x = x;\n",
        "        nodes[progr].y = y;\n",
        "\n",
        "    }\n",
        "\n",
        "    fclose(f);\n",
        "\n",
        "    TSPInstance instance = {.numOfNodes = num_of_nodes, .nodes = nodes};\n",
        "\n",
        "    float *edge_cost = malloc(sizeof(int) * num_of_nodes * num_of_nodes);\n",
        "\n",
        "    float deltaX, deltaY;\n",
        "    Node n1, n2;\n",
        "    float weight;\n",
        "    for (int i = 0; i < num_of_nodes; i++) {\n",
        "        for (int j = i; j < num_of_nodes; j++) {\n",
        "            n1 = nodes[i];\n",
        "            n2 = nodes[j];\n",
        "\n",
        "            deltaX = (float) (n1.x - n2.x);\n",
        "            deltaY = (float) (n1.y - n2.y);\n",
        "\n",
        "            weight = floorf(sqrtf(powf(deltaX, 2) + powf(deltaY,2)));\n",
        "\n",
        "            edge_cost[n1.id * num_of_nodes + n2.id] = weight;\n",
        "            edge_cost[n2.id * num_of_nodes + n1.id] = weight;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    instance.edgeCosts = edge_cost;\n",
        "    return instance;\n",
        "}\n",
        "\n",
        "void tsp_instance_free(TSPInstance *instance) {\n",
        "    free(instance->nodes);\n",
        "    free(instance->edgeCosts);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MJh4zi2eAQec",
        "outputId": "7aa4324e-1c00-4908-c244-50257bf40a77"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/sequential/tsplib.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv src/lib/sequential/tsplib.cu src/lib/sequential/tsplib.c"
      ],
      "metadata": {
        "id": "x3k0OZg0KHCx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Algorithm"
      ],
      "metadata": {
        "id": "jl0p9CZ4BAVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name lib/sequential/aco_tsp_sequential.h\n",
        "#ifndef ACO_TSP_SEQUENTIAL_H\n",
        "#define ACO_TSP_SEQUENTIAL_H\n",
        "\n",
        "#include \"tsplib.h\"\n",
        "\n",
        "void aco_tsp_sequential(\n",
        "    TSPInstance instance,\n",
        "    const float ALPHA,\n",
        "    const float BETA, \n",
        "    const float RHO, \n",
        "    const float Q, \n",
        "    const float PHEROMONE_LB, \n",
        "    const int MAX_ITERATIONS,\n",
        "    const int STAGNATION_THRESHOLD\n",
        ");\n",
        "\n",
        "#endif // ACO_TSP_SEQUENTIAL_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JrsnhpLyaLMS",
        "outputId": "22fa3175-1c5f-45b5-dbac-67f061f8f513"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/sequential/aco_tsp_sequential.h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cuda plugin requires .cu extension... change it later to .c\n",
        "# using %%cuda instead of %%writefile becaus writefile disables syntax highlighting\n",
        "\n",
        "%%cuda --name lib/sequential/aco_tsp_sequential.cu\n",
        "#include <stdio.h>\n",
        "#include <limits.h>\n",
        "#include <stdbool.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "\n",
        "#include \"aco_tsp_sequential.h\"\n",
        "\n",
        "float randf(float right) {\n",
        "    return ((float) rand() / (float) RAND_MAX) * right;\n",
        "}\n",
        "\n",
        "float pheromone_initialization(float *pheromones, const float *edge_cost, int N) {\n",
        "    /* BUILD greedy path */\n",
        "    int path[N];\n",
        "    float path_cost = 0;\n",
        "    bool visited[N];\n",
        "\n",
        "    int id_first_node = (int) random() % N;\n",
        "    visited[id_first_node] = true;\n",
        "\n",
        "    int current_node = id_first_node;\n",
        "    for (int i = 1; i < N; i++) {\n",
        "        int closest_node = -1;\n",
        "        float closest_node_cost = (float) INT_MAX;\n",
        "\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            if (!visited[j] && current_node != j && edge_cost[current_node * N + j] < closest_node_cost) {\n",
        "                closest_node_cost = edge_cost[current_node * N + j];\n",
        "                closest_node = j;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        path[current_node] = closest_node;\n",
        "        visited[closest_node] = true;\n",
        "        current_node = closest_node;\n",
        "        path_cost += closest_node_cost;\n",
        "    }\n",
        "\n",
        "    /* set pheromone to N/greedy path cost */\n",
        "    for (int i = 0; i < N * N; ++i)\n",
        "        pheromones[i] = (float) N / (float) path_cost;\n",
        "\n",
        "    \n",
        "}\n",
        "\n",
        "void build_paths(int *ant_paths_mx, float *pheromone_trails, float *edge_costs, int N, const float ALPHA, const float BETA) {\n",
        "    for (int i = 0; i < N * N; i++) ant_paths_mx[i] = -1;\n",
        "\n",
        "    bool *unvisited_nodes_mx = malloc(sizeof *unvisited_nodes_mx * N * N);\n",
        "    for (int i = 0; i < N * N; i++) unvisited_nodes_mx[i] = true;\n",
        "\n",
        "    float *edge_fitness_mx = malloc(sizeof *edge_fitness_mx *N * N);\n",
        "    for (int r = 0; r < N; ++r)\n",
        "      for (int c = 0; c < N; ++c)\n",
        "        edge_fitness_mx[r * N + c] =\n",
        "          r == c ? 0 : powf(pheromone_trails[r * N + c], ALPHA) / powf(edge_costs[r * N + c], BETA);\n",
        "\n",
        "    // build every ant's path\n",
        "    for (int ant_id = 0; ant_id < N; ++ant_id) {\n",
        "        // select random starting node\n",
        "        int id_first_node = (int) random() % N;\n",
        "        unvisited_nodes_mx[ant_id * N + id_first_node] = false;\n",
        "\n",
        "        int current_node_id = id_first_node;\n",
        "        for (int visited_nodes = 1; visited_nodes < N; visited_nodes++) {\n",
        "            float prefix_sum[N];\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                bool mask = unvisited_nodes_mx[ant_id * N + j];\n",
        "                float fitness = edge_fitness_mx[current_node_id * N + j];\n",
        "                prefix_sum[j] = (j > 0 ? prefix_sum[j - 1] : 0.0f) + ((float) mask * fitness);\n",
        "            }\n",
        "\n",
        "            float random_number = randf(prefix_sum[N - 1]);\n",
        "            for (int j = 0; j < N; ++j) {\n",
        "                float ps_prev = j > 0 ? prefix_sum[j - 1] : 0.0f;\n",
        "                if (random_number >= ps_prev && random_number < prefix_sum[j]) {\n",
        "                    ant_paths_mx[ant_id * N + current_node_id] = j;\n",
        "                    unvisited_nodes_mx[ant_id * N + j] = false;\n",
        "                    current_node_id = j;\n",
        "                    break;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        ant_paths_mx[ant_id * N + current_node_id] = id_first_node;\n",
        "    }\n",
        "\n",
        "    free(edge_fitness_mx);\n",
        "    free(unvisited_nodes_mx);\n",
        "}\n",
        "\n",
        "int update_paths_len(const int *ant_paths_mx, float *ant_paths_len, const float *edge_cost, int N) {\n",
        "    // keep track of the ant id with the shortest path\n",
        "    int best_path_ant_id = -1;\n",
        "    float best_path = (float) INT_MAX;\n",
        "\n",
        "    for (int ant_id = 0; ant_id < N; ++ant_id) {\n",
        "        // calculate cost of ant(ant_id) path\n",
        "        ant_paths_len[ant_id] = 0;\n",
        "        int current_node = 0;\n",
        "        int next_node = ant_paths_mx[ant_id * N + current_node];\n",
        "\n",
        "        for (int i = 0; i < N; ++i) {\n",
        "            ant_paths_len[ant_id] += edge_cost[current_node * N + next_node];\n",
        "            current_node = next_node;\n",
        "            next_node = ant_paths_mx[ant_id * N + current_node];\n",
        "        }\n",
        "\n",
        "        if (ant_paths_len[ant_id] < best_path) {\n",
        "            best_path = ant_paths_len[ant_id];\n",
        "            best_path_ant_id = ant_id;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return best_path_ant_id;\n",
        "}\n",
        "\n",
        "void pheromone_evaporation(float *pheromones, int N, const float RHO, const float PHEROMONE_LB) {\n",
        "    for (int i = 0; i < N * N; ++i)\n",
        "        pheromones[i] = fmaxf((1 - RHO) * pheromones[i], PHEROMONE_LB);\n",
        "}\n",
        "\n",
        "void pheromone_update(float *pheromones, const int *paths, const float *paths_len, int N, const float Q, const float PHEROMONE_LB) {\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = i; j < N; ++j) {\n",
        "            float previous_pheromone_value = pheromones[i * N + j];\n",
        "            float addition = 0.0f;\n",
        "            for (int ant_id = 0; ant_id < N; ++ant_id)\n",
        "                // if edge (i,j) is in path of ant ant_id\n",
        "                if (paths[ant_id * N + i] == j)\n",
        "                    addition += Q / (float) paths_len[ant_id];\n",
        "\n",
        "\n",
        "            pheromones[i * N + j] = fmaxf(previous_pheromone_value + addition, PHEROMONE_LB);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void aco_tsp_sequential(\n",
        "    TSPInstance instance,\n",
        "    const float ALPHA,\n",
        "    const float BETA, \n",
        "    const float RHO, \n",
        "    const float Q, \n",
        "    const float PHEROMONE_LB, \n",
        "    const int MAX_ITERATIONS,\n",
        "    const int STAGNATION_THRESHOLD\n",
        ")\n",
        "{\n",
        "    int N = instance.numOfNodes;\n",
        "    float *pheromone_mx = malloc(sizeof *pheromone_mx * N * N);\n",
        "    int   *paths_mx = malloc(sizeof *paths_mx *N * N);\n",
        "    float paths_len[N];\n",
        "    int best_path[N];\n",
        "    float best_path_len = (float) INT_MAX;\n",
        "\n",
        "    pheromone_initialization(pheromone_mx, instance.edgeCosts, N);\n",
        "    int stagnation_counter = 0;\n",
        "    for (int iter = 0; iter < MAX_ITERATIONS && stagnation_counter < STAGNATION_THRESHOLD; ++iter, ++stagnation_counter) {\n",
        "        printf(\"Generation %d of %d\", iter + 1, MAX_ITERATIONS);\n",
        "        fflush(stdout);\n",
        "      \n",
        "        build_paths(paths_mx, pheromone_mx, instance.edgeCosts, N, ALPHA, BETA);\n",
        "        int current_iteration_best_ant = update_paths_len(paths_mx, paths_len, instance.edgeCosts, N);\n",
        "\n",
        "        pheromone_evaporation(pheromone_mx, N, RHO, PHEROMONE_LB);\n",
        "        pheromone_update(pheromone_mx, paths_mx, paths_len, N, Q, PHEROMONE_LB);\n",
        "\n",
        "        if (paths_len[current_iteration_best_ant] < best_path_len) {\n",
        "            best_path_len = paths_len[current_iteration_best_ant];\n",
        "\n",
        "            // save best path\n",
        "            for (int l = 0; l < instance.numOfNodes; ++l)\n",
        "                best_path[l] = paths_mx[current_iteration_best_ant * N + l];\n",
        "\n",
        "            // there's an improvement reset stagnation counter\n",
        "            stagnation_counter = 0;\n",
        "        }\n",
        "\n",
        "        printf(\"\\r\");\n",
        "        fflush(stdout);\n",
        "    }\n",
        "    \n",
        "    free(pheromone_mx);\n",
        "    free(paths_mx);\n",
        "    \n",
        "    char *prefix = stagnation_counter == STAGNATION_THRESHOLD ? \"Stopped for stagnation!\\n\" : \"\";\n",
        "    printf(\"%sBest Path has len: %f\\n\", prefix, best_path_len);\n",
        "    for (int j = 0; j < instance.numOfNodes; ++j) printf(\"%d,\", best_path[j] + 1);\n",
        "    printf(\"\\n\");\n",
        "    fflush(stdout);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wEDt2dWFAWvq",
        "outputId": "e3cf0b79-8765-4548-b740-5dcd1995e36d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/sequential/aco_tsp_sequential.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/src/lib/sequential/aco_tsp_sequential.cu /content/src/lib/sequential/aco_tsp_sequential.c"
      ],
      "metadata": {
        "id": "-myfmsTlWmST"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GPU implementation"
      ],
      "metadata": {
        "id": "ns594U-lTx8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name lib/cuda/common.h\n",
        "#include <sys/time.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#ifndef _COMMON_H\n",
        "#define _COMMON_H\n",
        "\n",
        "#define CHECK(call)                                                            \\\n",
        "{                                                                              \\\n",
        "    const cudaError_t error = call;                                            \\\n",
        "    if (error != cudaSuccess)                                                  \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
        "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
        "                cudaGetErrorString(error));                                    \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CURAND(call)                                                     \\\n",
        "{                                                                              \\\n",
        "    curandStatus_t err;                                                        \\\n",
        "    if ((err = (call)) != CURAND_STATUS_SUCCESS)                               \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CURAND error %d at %s:%d\\n\", err, __FILE__,       \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#endif // _COMMON_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WCmYLZwKhss1",
        "outputId": "1a5d430e-25ed-4808-a696-3a21b588b307"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/cuda/common.h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm"
      ],
      "metadata": {
        "id": "CXmGFi4EXg6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name lib/cuda/aco_tsp_cuda.h\n",
        "#ifndef ACO_TSP_CUDA_H\n",
        "#define ACO_TSP_CUDA_H\n",
        "\n",
        "#include <curand_kernel.h>\n",
        "\n",
        "#include \"../sequential/tsplib.h\"\n",
        "#include \"./common.h\"\n",
        "\n",
        "#define DIV_ROUNDUP(NUM,DEN) ((NUM +(DEN-1))/DEN)\n",
        "\n",
        "void aco_tsp_cuda(\n",
        "    TSPInstance instance, \n",
        "    const float ALPHA,\n",
        "    const float BETA, \n",
        "    const float RHO, \n",
        "    const float Q, \n",
        "    const float PHEROMONE_LB, \n",
        "    const int MAX_ITERATIONS,\n",
        "    const int STAGNATION_THRESHOLD\n",
        ");\n",
        "\n",
        "#endif // ACO_TSP_CUDA_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "66GSPIswefn_",
        "outputId": "56fa2e72-d78e-45ae-c5ee-5badb7a541d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/cuda/aco_tsp_cuda.h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  %%cuda --name lib/cuda/aco_tsp_cuda.cu\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <assert.h>\n",
        "\n",
        "#include \"aco_tsp_cuda.h\"\n",
        "\n",
        "typedef enum { SCAN_INCLUSIVE, SCAN_EXCLUSIVE } PRESCAN_TYPE;\n",
        "\n",
        "__global__ void pheromone_reset(float *pheromone_mx, const int N, const float PHEROMONE_LB){\n",
        "    const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < N*N)\n",
        "      pheromone_mx[idx] = PHEROMONE_LB;\n",
        "}\n",
        "\n",
        "__global__ void init_random_states(curandState *randStates, const int bound){\n",
        "  const int gtid =blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if(gtid < bound)\n",
        "    curand_init(gtid, 0, 0, &randStates[gtid]);\n",
        "}\n",
        "\n",
        "__global__ void population_reset(\n",
        "  int *paths_mx, \n",
        "  bool *unvisited_nodes_mx,\n",
        "  int *ant_first_node, \n",
        "  int *ant_current_position, \n",
        "  curandState *randStates, \n",
        "  const int N\n",
        "){\n",
        "  const int gtid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "  if (gtid > N*N)\n",
        "    return;\n",
        "\n",
        "  paths_mx[gtid] = -1;\n",
        "\n",
        "  const int antId = gtid / N;\n",
        "  const int colId = gtid % N;\n",
        "  if (colId==0){\n",
        "    // abs is necessary because rand returns unsigned, and casting to signed gives overflow (negative numbers)\n",
        "    const int firstRandomNodeId = abs((int) curand(&randStates[gtid]) %N);\n",
        "    ant_first_node[antId] = firstRandomNodeId;\n",
        "    ant_current_position[antId] = firstRandomNodeId;\n",
        "    unvisited_nodes_mx[antId*N + firstRandomNodeId] = false;\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__ void unvisited_node_reset(bool *unvisited_node_mx, const int N){\n",
        "    const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < N*N)\n",
        "      unvisited_node_mx[idx] = true;\n",
        "}\n",
        "\n",
        "__global__ void edge_fitness_update(float *edge_fitness_mx, float *pheromone_mx, float *edge_costs_mx, const int N, const float ALPHA, const float BETA){\n",
        "    const int gidx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    float edge_cost = edge_costs_mx[gidx];\n",
        "    float pheromone = pheromone_mx[gidx];\n",
        "    if (gidx < N*N && edge_cost>0 && pheromone>0)\n",
        "      edge_fitness_mx[gidx] = powf(pheromone, ALPHA) / powf(edge_cost, BETA);\n",
        "}\n",
        "\n",
        "/*\n",
        "  prescan (in-place)\n",
        "  --------------------------------------------------------------------------------\n",
        "  Slightly modified version of Blelloch's prefix scan to allow for inclusive scan.\n",
        "  Pretend the array to sum is always a multiple of blocksize: parameter bound will \n",
        "    prevent illigel access to memory. Out of bound data in the original array\n",
        "    will be represented in shared memory with a 0 (which is neutral to prefix sum)\n",
        "    so the method can handle arrays of arbitrary size with minor modifications \n",
        "    (check if global thread id < bound).\n",
        "\n",
        "  LAUNCH PARAMETERS: \n",
        "    Having N elements. Block size = B:\n",
        "      ceil(N/B)   blocks \n",
        "      b/2         threads \n",
        "      (N/B)+1     floats in shared memory\n",
        "  PARAMETERS:\n",
        "    *data         array to prefix sum\n",
        "    n             number of elements in each block\n",
        "    *blockSum     output of each block final sum. Used to calculate prescan with multiple blocks.\n",
        "    SCAN_TYPE     flag to specify is sum is inlcusive or exclusive\n",
        "    bound         number of elements in the entire array\n",
        "*/\n",
        "__global__ void prescan(float *data, const int n, float *blockSum, const PRESCAN_TYPE SCAN_TYPE, const int bound) { \n",
        "  extern __shared__ float sm[];\n",
        "  \n",
        "  const int tid = threadIdx.x;\n",
        "  const int gtid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int offset = 1;\n",
        "    \n",
        "  /* Load input into shared memory. Threads that exceed the actual array size\n",
        "  *  are zeroed out so they do not influence the correct scan result.\n",
        "  */\n",
        "  sm[2*tid] = 0;\n",
        "  sm[2*tid+1] = 0;\n",
        "  if(2*gtid < bound)\n",
        "    sm[2*tid] = data[2*gtid]; \n",
        "  if(2*gtid +1 < bound)\n",
        "    sm[2*tid+1] = data[2*gtid+1];\n",
        "  \n",
        "  // build sum in place up the tree\n",
        "  for (int d = n>>1; d > 0; d >>= 1) {\n",
        "    __syncthreads();\n",
        "\n",
        "    if (tid < d) { \n",
        "      int ai = offset*(2*tid+1)-1;\n",
        "      int bi = offset*(2*tid+2)-1;\n",
        "      sm[bi] += sm[ai];\n",
        "    }\n",
        "    offset *= 2;\n",
        "  }\n",
        "\n",
        "  if (tid == 0) { \n",
        "    if(SCAN_TYPE == SCAN_INCLUSIVE)\n",
        "      sm[n] = sm[n-1]; \n",
        "\n",
        "    if(blockSum!=NULL)\n",
        "      blockSum[blockIdx.x] = sm[n-1];\n",
        "\n",
        "    sm[n-1] = 0.0f;\n",
        "  }\n",
        "\n",
        "  // traverse down tree & build scan \n",
        "  for (int d = 1; d < n; d *= 2) {      \n",
        "    offset >>= 1;\n",
        "    __syncthreads();\n",
        "    if (tid < d) {\n",
        "      int ai = offset*(2*tid+1)-1;\n",
        "      int bi = offset*(2*tid+2)-1;\n",
        "      float t = sm[ai]; sm[ai] = sm[bi]; sm[bi] += t;\n",
        "    }\n",
        "  }\n",
        "  \n",
        "  __syncthreads();\n",
        "\n",
        "  int shift=0;\n",
        "  if(SCAN_TYPE == SCAN_INCLUSIVE)\n",
        "    shift =1;\n",
        "\n",
        "  if(2*gtid < bound)\n",
        "    data[2*gtid] = sm[2*tid+shift];\n",
        "  if(2*gtid +1 < bound)\n",
        "    data[2*gtid+1] = sm[2*tid+1+shift];\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void apply_increment(float *cumsum, float *increment, const int n){\n",
        "  int gidx = blockIdx.x*blockDim.x +threadIdx.x;\n",
        "\n",
        "  if(gidx < n)\n",
        "    cumsum[gidx] += increment[blockIdx.x];\n",
        "}\n",
        "\n",
        "__global__ void apply_mask(float *data, bool *mask, const int N){\n",
        "    const int gtid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (gtid<N)\n",
        "      data[gtid] *= mask[gtid];\n",
        "}\n",
        "\n",
        "__global__ void select_node(\n",
        "  float *fitness, \n",
        "  float *randomNumber,\n",
        "  int *antPathsMx,\n",
        "  bool *unvisited_nodes_mx,\n",
        "  int *antsCurrentPosition,\n",
        "  const int N,\n",
        "  const int antId\n",
        "){\n",
        "  extern __shared__ float sm[];\n",
        "  const int gtid = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "  const int tid = threadIdx.x;\n",
        "\n",
        "  if (gtid >= N)\n",
        "    return;\n",
        "\n",
        "  /* compiler will do its magic to avoid branching */\n",
        "  if(tid==0)\n",
        "    if(gtid==0)\n",
        "      sm[tid] = 0.0f;\n",
        "    else\n",
        "      sm[tid] = fitness[gtid-1];\n",
        "  \n",
        "  sm[tid+1] = fitness[gtid];\n",
        "  __syncthreads();\n",
        "\n",
        "  // for the properties of the prefix sum and the range of the random number, \n",
        "  // only one thread will enter this if\n",
        "\n",
        "  if(randomNumber[0] >= sm[tid] && randomNumber[0] < sm[tid+1]){\n",
        "    int antCurrentNodeId = antsCurrentPosition[antId];\n",
        "    int selectedNodeId = gtid;\n",
        "    \n",
        "    // update ant path\n",
        "    antPathsMx[antId*N + antCurrentNodeId] = selectedNodeId; \n",
        "\n",
        "    // set node as visited\n",
        "    unvisited_nodes_mx[antId*N + selectedNodeId] = false;\n",
        "\n",
        "    // update current node\n",
        "    antsCurrentPosition[antId] = selectedNodeId;\n",
        "  }\n",
        "\n",
        "  if(gtid == 0 && randomNumber[0]==0.0){\n",
        "    int antCurrentNodeId = antsCurrentPosition[antId];\n",
        "    int selectedNodeId = gtid;\n",
        "    \n",
        "    // update ant path\n",
        "    antPathsMx[antId*N + antCurrentNodeId] = selectedNodeId; \n",
        "\n",
        "    // set node as visited\n",
        "    unvisited_nodes_mx[antId*N + selectedNodeId] = false;\n",
        "\n",
        "    // update current node\n",
        "    antsCurrentPosition[antId] = selectedNodeId;\n",
        "  }\n",
        "}\n",
        "\n",
        "int closest_multiple_of(int numToRound, int multiple){\n",
        "  assert(numToRound >0);\n",
        "\n",
        "  if (multiple == 0)\n",
        "    return numToRound;\n",
        "\n",
        "  int remainder = numToRound % multiple;\n",
        "  if (remainder == 0)\n",
        "    return numToRound;\n",
        "\n",
        "  return numToRound + multiple - remainder;\n",
        "}\n",
        "\n",
        "int next_power_of_two(int n){\n",
        "    int res=1;\n",
        "    while(res<n) {res <<= 1;}\n",
        "    return res;\n",
        "}\n",
        "\n",
        "void set_prefixsum_launch_configuration(dim3 *gridConf, dim3 *blockConf, const int BLOCKSIZE, const int N){\n",
        "  gridConf->x = N/BLOCKSIZE;\n",
        "\n",
        "  /* if the size of the array is not a multiple of block size, add one extra block to handle\n",
        "  *  the last elements (even though the last threads will do useless work...).\n",
        "  *  this is necessary to handle arbitrary size arrays \n",
        "  */\n",
        "  if(N%BLOCKSIZE != 0)\n",
        "    gridConf->x += 1;\n",
        "\n",
        "  blockConf->x = BLOCKSIZE/2;\n",
        "}\n",
        "\n",
        "void set_linear_operations_launch_configuration(dim3 *gridConf, dim3 *blockConf, const int BLOCKSIZE, const int N){\n",
        "  gridConf->x = DIV_ROUNDUP(N*N,BLOCKSIZE);\n",
        "  blockConf->x = BLOCKSIZE;\n",
        "}\n",
        "\n",
        "__global__ void pheromone_evaporation(float *pheromone_mx, const int N, const float RHO, const float PHEROMONE_LB){\n",
        "    const int gtid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    if(gtid <N*N)\n",
        "      pheromone_mx[gtid] = fmaxf((1 - RHO) * pheromone_mx[gtid], PHEROMONE_LB);\n",
        "}\n",
        "\n",
        "__global__ void generate_random_number_in_range(float *maxVal, float *output, curandState *randState){\n",
        "  output[0] = (curand_uniform(randState)-0.0000000001) * maxVal[0] ;\n",
        "  //output[0] = curand_uniform(randState) * maxVal[0] ;\n",
        "}\n",
        "\n",
        "__global__ void close_loop(int *antPaths, int *firstNodes, int *currentPosition, const int N){\n",
        "  const int antId = blockDim.x *blockIdx.x + threadIdx.x;\n",
        "\n",
        "  const int current = currentPosition[antId];\n",
        "  const int first = firstNodes[antId];\n",
        "\n",
        "  if(antId < N)\n",
        "    antPaths[antId*N + current] = first;\n",
        "}\n",
        "\n",
        "#include <termios.h>\n",
        "#include <unistd.h>\n",
        "int mygetch ( void ) \n",
        "{\n",
        "  int ch;\n",
        "  struct termios oldt, newt;\n",
        "  \n",
        "  tcgetattr ( STDIN_FILENO, &oldt );\n",
        "  newt = oldt;\n",
        "  newt.c_lflag &= ~( ICANON | ECHO );\n",
        "  tcsetattr ( STDIN_FILENO, TCSANOW, &newt );\n",
        "  ch = getchar();\n",
        "  tcsetattr ( STDIN_FILENO, TCSANOW, &oldt );\n",
        "  \n",
        "  return ch;\n",
        "}\n",
        "\n",
        "\n",
        "void aco_tsp_cuda(\n",
        "    TSPInstance instance,\n",
        "    const float ALPHA,\n",
        "    const float BETA, \n",
        "    const float RHO, \n",
        "    const float Q, \n",
        "    const float PHEROMONE_LB, \n",
        "    const int MAX_ITERATIONS,\n",
        "    const int STAGNATION_THRESHOLD\n",
        ") \n",
        "{\n",
        "  /* instance size defines size of most data structures (arrays and matrices) */\n",
        "  const int N = instance.numOfNodes;\n",
        "  const size_t NN_INT_SIZE = sizeof(int)*N*N;\n",
        "  const size_t NN_FLOAT_SIZE = sizeof(float)*N*N;\n",
        "  const size_t NN_BOOL_SIZE = sizeof(bool)*N*N;\n",
        " \n",
        "  const size_t N_INT_SIZE = sizeof(int) * N;\n",
        "  const size_t N_FLOAT_SIZE = sizeof(float)*N;\n",
        "\n",
        "/*DEV**********************************/\n",
        "  float *h_debugFloatMx = (float *) malloc(NN_FLOAT_SIZE);\n",
        "  int *h_debugIntMx = (int *) malloc(NN_INT_SIZE);\n",
        "  bool *h_debugBoolMx = (bool *) malloc(NN_BOOL_SIZE);\n",
        "  \n",
        "  float *h_debug1 = (float *) malloc(NN_FLOAT_SIZE); \n",
        "  float *h_debug2 = (float *) malloc(NN_FLOAT_SIZE);\n",
        "/***********************************/\n",
        "\n",
        "  const int BLOCKSIZE = 64;\n",
        "  \n",
        "  /* DEVICE */\n",
        "  float *d_pheromone_mx;\n",
        "  int   *d_paths_mx;\n",
        "  bool  *d_unvisited_nodes_mx;\n",
        "  float *d_edge_costs_mx;\n",
        "  float *d_edge_fitness_mx;\n",
        " \n",
        "  int   *d_ant_first_node;\n",
        "  int   *d_ant_current_position;\n",
        "  float *d_random_numbers;\n",
        " \n",
        "  CHECK(cudaMalloc((void **)&d_pheromone_mx,        NN_FLOAT_SIZE));\n",
        "  CHECK(cudaMalloc((void **)&d_paths_mx,            NN_INT_SIZE));\n",
        "  CHECK(cudaMalloc((void **)&d_edge_costs_mx,       NN_FLOAT_SIZE));\n",
        "  CHECK(cudaMalloc((void **)&d_edge_fitness_mx,     NN_FLOAT_SIZE));\n",
        "  CHECK(cudaMalloc((void **)&d_unvisited_nodes_mx,  NN_BOOL_SIZE));\n",
        "  CHECK(cudaMalloc((void **)&d_ant_current_position,N_INT_SIZE));\n",
        "  CHECK(cudaMalloc((void **)&d_ant_first_node,      N_INT_SIZE));\n",
        "  CHECK(cudaMalloc((void **)&d_random_numbers,      N_FLOAT_SIZE));\n",
        " \n",
        "  CHECK(cudaMemcpy(d_edge_costs_mx, instance.edgeCosts, NN_FLOAT_SIZE, cudaMemcpyHostToDevice));\n",
        "  \n",
        "  /* for all the simple kernels that work on the N*N vector */\n",
        "  dim3 linOpGridConf, linOpBlockConf;\n",
        "  set_linear_operations_launch_configuration(&linOpGridConf, &linOpBlockConf, BLOCKSIZE, N);\n",
        "  \n",
        "  /* for the prefix sum calculation */\n",
        "  dim3 prescanGridConf, prescanBlockConf;\n",
        "  set_prefixsum_launch_configuration(&prescanGridConf, &prescanBlockConf, BLOCKSIZE, N);\n",
        "  float *d_intermediary_sums_v;\n",
        "  CHECK(cudaMalloc((void **)&d_intermediary_sums_v, sizeof(float)*prescanGridConf.x)); \n",
        "  \n",
        "  printf(\"Matrices of size %dx%d\\n\", N, N);\n",
        "  printf(\"Linear operations kernels launch config: %d blocks of %d threads\\n\", linOpGridConf.x, linOpBlockConf.x);\n",
        "  printf(\"Prefix scan kernels launch config: %d blocks of %d threads\\n\", prescanGridConf.x, prescanBlockConf.x);\n",
        "  \n",
        "  pheromone_reset<<<linOpGridConf, linOpBlockConf>>>(d_pheromone_mx, N, PHEROMONE_LB);\n",
        " \n",
        "  curandState *d_randStates;\n",
        "  CHECK(cudaMalloc((void **) &d_randStates, linOpGridConf.x * linOpBlockConf.x * sizeof(d_randStates)));\n",
        "  init_random_states<<<linOpGridConf, linOpBlockConf>>>(d_randStates, N*N);\n",
        "  \n",
        "  int stagnation_counter = 0;\n",
        "  for (int iter = 0; iter < MAX_ITERATIONS && stagnation_counter < STAGNATION_THRESHOLD; ++iter, ++stagnation_counter) {\n",
        "    printf(\"Generation %d of %d\", iter + 1, MAX_ITERATIONS);\n",
        "    fflush(stdout);\n",
        "/*******BUILD PATHS******************/\n",
        "      \n",
        "    /* reset(or update) all data from previous iteration */\n",
        "    CHECK(cudaMemset(d_ant_current_position, 0, N_INT_SIZE));\n",
        "    CHECK(cudaMemset(d_ant_first_node, 0, N_INT_SIZE));\n",
        "\n",
        "    unvisited_node_reset<<<linOpGridConf, linOpBlockConf>>>(d_unvisited_nodes_mx, N);\n",
        "    population_reset<<<linOpGridConf, linOpBlockConf>>>(\n",
        "        d_paths_mx,\n",
        "        d_unvisited_nodes_mx,\n",
        "        d_ant_first_node,\n",
        "        d_ant_current_position, \n",
        "        d_randStates, \n",
        "        N\n",
        "    );\n",
        "    edge_fitness_update<<<linOpGridConf, linOpBlockConf>>>(d_edge_fitness_mx, d_pheromone_mx, d_edge_costs_mx, N, ALPHA, BETA);\n",
        "\n",
        "    for(int antId = 0; antId < N; antId++){\n",
        "      for (int visited_nodes = 1; visited_nodes < N; visited_nodes++) {\n",
        "        apply_mask<<<prescanGridConf, prescanBlockConf.x*2>>>(&d_edge_fitness_mx[antId*N], &d_unvisited_nodes_mx[antId*N], N);\n",
        "        \n",
        "        // calculate probability of picking each node using prefix sum\n",
        "        prescan<<<prescanGridConf, prescanBlockConf, sizeof(float)*(BLOCKSIZE+1)>>>(&d_edge_fitness_mx[antId*N], BLOCKSIZE, d_intermediary_sums_v, SCAN_INCLUSIVE, N);\n",
        "        if(prescanGridConf.x>1){ // meaning prefix sum is split in multiple blocks\n",
        "          prescan<<<1,prescanBlockConf,sizeof(float)*prescanBlockConf.x>>>(d_intermediary_sums_v, prescanBlockConf.x, NULL, SCAN_EXCLUSIVE, prescanGridConf.x);\n",
        "          apply_increment<<<prescanGridConf, prescanBlockConf.x*2>>>(&d_edge_fitness_mx[antId*N], d_intermediary_sums_v, N);\n",
        "        }\n",
        "\n",
        "        //CHECK(cudaMemcpy(h_debugFloatMx, d_edge_fitness_mx, NN_FLOAT_SIZE, cudaMemcpyDeviceToHost));\n",
        "        //printf(\"prescan fitness\\n\");\n",
        "        //for(int row=0; row<N; row++){\n",
        "        //    for(int col=0; col<N; col++){\n",
        "        //        printf(\"%f \", h_debugFloatMx[row*N +col]);\n",
        "        //    }\n",
        "        //    printf(\"\\n\");\n",
        "        //}\n",
        "\n",
        "        generate_random_number_in_range<<<1,1>>>(\n",
        "          &d_edge_fitness_mx[antId*N+N-1], \n",
        "          &d_random_numbers[antId], \n",
        "          &d_randStates[antId]\n",
        "        );\n",
        "\n",
        "        select_node<<<prescanGridConf, prescanBlockConf.x*2, sizeof(float)*((prescanBlockConf.x*2)+1)>>>(\n",
        "          &d_edge_fitness_mx[antId*N], \n",
        "          &d_random_numbers[antId],\n",
        "          d_paths_mx,\n",
        "          d_unvisited_nodes_mx,\n",
        "          d_ant_current_position,  \n",
        "          N,\n",
        "          antId\n",
        "        );\n",
        "        //printf(\"\\n\");\n",
        "        //mygetch();\n",
        "      }\n",
        "    }\n",
        "\n",
        "    close_loop<<<prescanGridConf, prescanBlockConf.x*2>>>(d_paths_mx, d_ant_first_node, d_ant_current_position, N);\n",
        "\n",
        "          CHECK(cudaMemcpy(h_debugIntMx, d_paths_mx, NN_INT_SIZE, cudaMemcpyDeviceToHost));\n",
        "          printf(\"Population after path has been build\\n[\");\n",
        "          for(int row=0; row<N; row++){\n",
        "              printf(\"[\");\n",
        "              for(int col=0; col<N; col++){\n",
        "                  printf(\"%d, \", h_debugIntMx[row*N +col]);\n",
        "              }\n",
        "              printf(\"]\\n\");\n",
        "          }\n",
        "          printf(\"]\");\n",
        "\n",
        "    break;\n",
        "/*END BUILD PATHS******************/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    //printf(\"\\r\");\n",
        "    fflush(stdout);\n",
        "  }    \n",
        "\n",
        "    /*\n",
        "    printf(\"%sBest Path has len: %f\\n\", stagnation_counter == STAGNATION_THRESHOLD ? \"Stopped for stagnation!\" :\"\", best_path_len);\n",
        "    for (int j = 0; j < instance.numOfNodes; ++j) printf(\"%d,\", best_path[j] + 1);\n",
        "    printf(\"\\n\");\n",
        "    fflush(stdout);\n",
        "    */\n",
        "\n",
        "  free(h_debugFloatMx);\n",
        "  free(h_debugIntMx);\n",
        "  free(h_debug1);\n",
        "  free(h_debug2);\n",
        "  free(h_debugBoolMx);\n",
        "\n",
        "  CHECK(cudaDeviceSynchronize());\n",
        "    \n",
        "  cudaFree(d_pheromone_mx);\n",
        "  cudaFree(d_paths_mx);\n",
        "  cudaFree(d_unvisited_nodes_mx);\n",
        "  cudaFree(d_edge_costs_mx);\n",
        "  cudaFree(d_edge_fitness_mx);\n",
        "  cudaFree(d_intermediary_sums_v);\n",
        "  cudaFree(d_randStates);\n",
        "  cudaFree(d_ant_current_position);\n",
        "  cudaFree(d_ant_first_node);\n",
        "  cudaFree(d_random_numbers);\n",
        "\n",
        "  CHECK(cudaDeviceReset());\n",
        "}\n"
      ],
      "metadata": {
        "id": "0xAWDFX-79iX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ede0a1db-4ca6-4826-d912-7024e324c98b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/cuda/aco_tsp_cuda.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Glue"
      ],
      "metadata": {
        "id": "1eO7fmrhZDqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/CMakeLists.txt\n",
        "cmake_minimum_required(VERSION 3.21)\n",
        "project(ACO_TSP LANGUAGES CUDA C)\n",
        "\n",
        "#######################\n",
        "###   SEQUENTIAL\n",
        "add_library(\n",
        "  aco_tsp_sequential STATIC \n",
        "  \n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/sequential/tsplib.h\n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/sequential/tsplib.c \n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/sequential/aco_tsp_sequential.h \n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/sequential/aco_tsp_sequential.c \n",
        ")\n",
        "\n",
        "target_include_directories(aco_tsp_sequential PUBLIC ${CMAKE_CURRENT_SOURCE_DIR})\n",
        "\n",
        "#######################\n",
        "###   CUDA\n",
        "\n",
        "set(CUDA_SEPARABLE_COMPILATION ON)\n",
        "\n",
        "add_library(\n",
        "  aco_tsp_cuda STATIC \n",
        "\n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/cuda/aco_tsp_cuda.h\n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/cuda/aco_tsp_cuda.cu \n",
        "  \n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/cuda/common.h\n",
        ")\n",
        "target_include_directories (aco_tsp_cuda PUBLIC ${CMAKE_CURRENT_SOURCE_DIR})\n",
        "set_target_properties(aco_tsp_cuda PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n",
        "\n",
        "\n",
        "########### MAIN ###########\n",
        "add_executable(ACO_TSP main.cu)\n",
        "\n",
        "target_compile_options(ACO_TSP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:\n",
        "                       --generate-line-info\n",
        "                       --use_fast_math\n",
        "                       --relocatable-device-code=true\n",
        "                       -arch=sm_75\n",
        "                       >)\n",
        "\n",
        "target_link_libraries(${PROJECT_NAME} PUBLIC m)\n",
        "target_link_libraries(${PROJECT_NAME} PUBLIC aco_tsp_cuda)\n",
        "target_link_libraries(${PROJECT_NAME} PUBLIC aco_tsp_sequential)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd2bR56ZRUyJ",
        "outputId": "bff3373f-eaea-473e-d645-e58546c835e6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/CMakeLists.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name main.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "extern \"C\" { \n",
        "  #include \"./lib/sequential/tsplib.h\"\n",
        "  #include \"./lib/sequential/aco_tsp_sequential.h\"\n",
        "}\n",
        "#include \"./lib/cuda/aco_tsp_cuda.h\"\n",
        "\n",
        "\n",
        "#define RUN_CPU false\n",
        "#define RUN_GPU true\n",
        "\n",
        "#define BASE_DATA_FOLDER \"/content/data/\"\n",
        "\n",
        "/*\n",
        "ALPHA importance of pheromone trail\n",
        "BETA  importance of heuristic visibility\n",
        "RHO   pheromone evaporation rate\n",
        "Q     numerator of pheromone update\n",
        "*/\n",
        "static const float ALPHA = 1.0f;\n",
        "static const float BETA = 3.0f;\n",
        "static const float RHO = 0.8f;\n",
        "static const float Q = 1.0f;\n",
        "static const float PHEROMONE_LB = 99.01f;\n",
        "static const int MAX_ITERATIONS = 10000;\n",
        "static const int STAGNATION_THRESHOLD = MAX_ITERATIONS/5;\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "  if (argc<2){\n",
        "    printf(\"Specify filname\\n\");\n",
        "    return -1;\n",
        "  }\n",
        "\n",
        "  char filenameBuffer[128];\n",
        "  strcpy(filenameBuffer, BASE_DATA_FOLDER);\n",
        "  strcat(filenameBuffer, argv[1]);\n",
        "    \n",
        "  TSPInstance instance = tsp_instance_read(filenameBuffer);\n",
        "\n",
        "  int cpu_msec, gpu_msec;\n",
        "  if(RUN_CPU){\n",
        "    printf(\"RUNNING CPU\\n\");\n",
        "    srand(time(NULL));\n",
        "    \n",
        "    clock_t starts = clock(), diffs;\n",
        "    \n",
        "    aco_tsp_sequential(instance, ALPHA, BETA, RHO, Q, PHEROMONE_LB, MAX_ITERATIONS, STAGNATION_THRESHOLD);\n",
        "    \n",
        "    diffs = clock() - starts;\n",
        "    cpu_msec = diffs * 1000 / CLOCKS_PER_SEC;\n",
        "  }\n",
        "\n",
        "\n",
        "  if(RUN_GPU){\n",
        "    printf(\"RUNNING GPU\\n\");\n",
        "    cudaSetDevice(1);\n",
        "    clock_t startc = clock(), diffc;\n",
        "\n",
        "    aco_tsp_cuda(instance, ALPHA, BETA, RHO, Q, PHEROMONE_LB, MAX_ITERATIONS, STAGNATION_THRESHOLD);\n",
        "    cudaDeviceSynchronize();\n",
        "    \n",
        "    diffc = clock() - startc;\n",
        "    gpu_msec = diffc * 1000 / CLOCKS_PER_SEC;\n",
        "  }\n",
        "  printf(\"\\n\");\n",
        "  if(RUN_CPU) printf(\"CPU\\t\\t%d sec. %d msec.\\n\", cpu_msec/1000, cpu_msec%1000);\n",
        "  if(RUN_GPU) printf(\"GPU\\t\\t%d sec. %d msec.\\n\", gpu_msec/1000, gpu_msec%1000);\n",
        "  \n",
        "  if(RUN_CPU && RUN_GPU){\n",
        "    float speedup = (float) cpu_msec/ (float) gpu_msec;\n",
        "    printf(\"SPEEDUP:\\t%f\", speedup);\n",
        "  }\n",
        "\n",
        "\n",
        "  tsp_instance_free(&instance);\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ugQP-dqeLRTG",
        "outputId": "937de204-7111-4e5b-e6e8-d13e814c91d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/main.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Compile & Run"
      ],
      "metadata": {
        "id": "IuvHRxGIIhVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p cmake_build\n",
        "%cd cmake_build\n",
        "\n",
        "!cmake ../src\n",
        "!cmake --build .\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd9YRaN1e_LW",
        "outputId": "5f61ab33-8165-465c-8844-6e6b6281c5a0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cmake_build\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/cmake_build\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target aco_tsp_sequential\u001b[0m\n",
            "[ 37%] Built target aco_tsp_sequential\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target aco_tsp_cuda\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CUDA object CMakeFiles/aco_tsp_cuda.dir/lib/cuda/aco_tsp_cuda.cu.o\u001b[0m\n",
            "[ 62%] \u001b[32m\u001b[1mLinking CUDA static library libaco_tsp_cuda.a\u001b[0m\n",
            "[ 62%] Built target aco_tsp_cuda\n",
            "[ 75%] \u001b[32mBuilding CUDA object CMakeFiles/ACO_TSP.dir/main.cu.o\u001b[0m\n",
            "[ 87%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/ACO_TSP.dir/cmake_device_link.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CUDA executable ACO_TSP\u001b[0m\n",
            "[100%] Built target ACO_TSP\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./cmake_build/ACO_TSP att48.tsp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6A8O6SeS8uq",
        "outputId": "0fecff0a-0c82-459f-b5a2-d18f20029ff6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading tsplib instances from /content/data/att48.tsp\n",
            "RUNNING GPU\n",
            "Matrices of size 48x48\n",
            "Linear operations kernels launch config: 36 blocks of 64 threads\n",
            "Prefix scan kernels launch config: 1 blocks of 32 threads\n",
            "Generation 1 of 10000Population after path has been build\n",
            "[[10, 0, 1, 2, 3, 4, 5, 6, 31, 7, 8, 12, 9, 11, 16, 13, 15, 18, 14, 17, 19, 20, 21, 27, 41, 24, 23, 22, 26, 32, 28, 25, 30, 35, 36, 29, 39, 40, 42, 33, 47, 38, 37, 44, 34, 46, 43, 45, ]\n",
            "[10, 2, 0, 1, 5, 3, 4, 6, 7, 8, 28, 9, 11, 17, 12, 14, 15, 16, 13, 18, 21, 19, 20, 22, 46, 23, 29, 25, 41, 27, 44, 34, 36, 37, 35, 26, 47, 31, 24, 30, 39, 38, 40, 45, 43, 33, 32, 42, ]\n",
            "[46, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 11, 12, 30, 44, 14, 17, 21, 22, 18, 19, 24, 38, 20, 25, 28, 26, 27, 16, 29, 31, 35, 41, 32, 37, 43, 40, 42, 45, 36, 34, 33, 23, 47, 15, 39, ]\n",
            "[46, 0, 1, 2, 3, 4, 5, 6, 9, 7, 8, 12, 10, 14, 11, 16, 13, 18, 15, 20, 17, 23, 26, 19, 22, 37, 21, 28, 24, 36, 29, 32, 30, 41, 38, 31, 27, 47, 33, 35, 45, 42, 39, 34, 43, 44, 25, 40, ]\n",
            "[10, 0, 1, 2, 3, 4, 5, 6, 9, 7, 47, 12, 8, 11, 13, 14, 15, 16, 17, 18, 24, 19, 21, 27, 22, 20, 37, 25, 38, 30, 31, 23, 34, 39, 40, 43, 32, 41, 33, 29, 28, 45, 44, 42, 36, 46, 35, 26, ]\n",
            "[26, 0, 1, 2, 6, 3, 5, 4, 7, 8, 9, 10, 11, 12, 16, 13, 15, 14, 17, 21, 18, 20, 23, 19, 22, 24, 29, 25, 30, 34, 31, 27, 42, 28, 36, 33, 32, 44, 43, 35, 38, 40, 46, 39, 45, 41, 47, 37, ]\n",
            "[18, 0, 1, 2, 3, 4, 5, 6, 9, 7, 8, 12, 10, 11, 13, 14, 17, 15, 27, 16, 24, 19, 25, 26, 28, 21, 22, 44, 23, 20, 29, 47, 36, 37, 45, 33, 41, 30, 32, 40, 35, 46, 34, 42, 43, 31, 39, 38, ]\n",
            "[46, 30, 3, 1, 2, 4, 5, 6, 7, 12, 8, 9, 10, 15, 13, 11, 18, 14, 17, 16, 19, 22, 20, 21, 23, 26, 31, 24, 27, 33, 0, 28, 35, 32, 36, 25, 37, 41, 45, 38, 43, 40, 39, 42, 34, 29, 47, 44, ]\n",
            "[35, 6, 1, 2, 3, 4, 0, 5, 7, 8, 9, 10, 11, 33, 12, 14, 15, 16, 20, 21, 17, 18, 19, 24, 22, 26, 23, 34, 25, 30, 28, 47, 29, 45, 43, 13, 32, 36, 39, 40, 44, 31, 41, 37, 46, 42, 27, 38, ]\n",
            "[42, 10, 0, 4, 2, 3, 5, 6, 7, 8, 40, 9, 11, 37, 12, 14, 15, 16, 17, 20, 18, 19, 13, 21, 25, 23, 24, 26, 30, 31, 27, 28, 29, 38, 36, 32, 35, 43, 39, 34, 22, 47, 1, 44, 46, 33, 41, 45, ]\n",
            "[14, 0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 9, 10, 12, 46, 13, 17, 15, 21, 20, 16, 19, 18, 25, 23, 22, 40, 37, 44, 27, 24, 30, 41, 36, 35, 43, 32, 39, 34, 31, 29, 47, 38, 45, 42, 33, 28, 26, ]\n",
            "[34, 0, 1, 2, 3, 4, 5, 6, 9, 7, 11, 8, 13, 10, 31, 12, 18, 15, 17, 16, 19, 20, 23, 21, 32, 45, 22, 38, 44, 26, 47, 37, 29, 28, 14, 39, 46, 25, 33, 27, 41, 36, 35, 42, 24, 30, 43, 40, ]\n",
            "[26, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 46, 21, 18, 17, 16, 37, 19, 23, 24, 20, 25, 27, 28, 31, 29, 30, 36, 33, 43, 32, 38, 34, 41, 44, 22, 35, 39, 45, 47, 40, 42, ]\n",
            "[42, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 14, 15, 20, 18, 17, 19, 21, 22, 25, 40, 23, 32, 26, 38, 34, 28, 31, 39, 47, 45, 33, 35, 44, 27, 29, 43, 24, 37, 41, 46, 30, 36, ]\n",
            "[46, 2, 0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 13, 11, 12, 17, 14, 16, 15, 18, 19, 22, 20, 26, 21, 23, 24, 29, 43, 25, 44, 36, 39, 41, 40, 34, 45, 30, 47, 31, 33, 28, 35, 27, 38, 42, 37, 32, ]\n",
            "[47, 34, 1, 2, 3, 4, 5, 6, 7, 12, 8, 13, 10, 9, 11, 14, 15, 16, 17, 18, 19, 20, 23, 21, 26, 22, 27, 25, 24, 35, 46, 33, 28, 32, 0, 38, 37, 29, 30, 36, 31, 40, 45, 44, 41, 39, 43, 42, ]\n",
            "[42, 0, 1, 2, 3, 4, 5, 6, 7, 10, 8, 9, 11, 12, 13, 16, 14, 15, 17, 18, 19, 20, 21, 25, 22, 39, 41, 24, 30, 23, 31, 29, 36, 38, 28, 40, 47, 35, 43, 27, 33, 32, 26, 34, 45, 37, 44, 46, ]\n",
            "[26, 0, 1, 2, 3, 4, 16, 5, 9, 7, 8, 12, 10, 11, 13, 14, 25, 15, 17, 18, 22, 20, 19, 21, 23, 29, 6, 36, 24, 37, 31, 34, 28, 27, 32, 38, 30, 41, 33, 43, 39, 46, 40, 35, 42, 44, 47, 45, ]\n",
            "[46, 2, 0, 1, 3, 4, 5, 6, 10, 7, 9, 8, 11, 12, 13, 14, 15, 20, 19, 16, 18, 31, 25, 17, 23, 24, 39, 21, 40, 33, 45, 22, 37, 36, 38, 28, 27, 47, 32, 30, 29, 42, 43, 35, 41, 34, 26, 44, ]\n",
            "[18, 0, 1, 2, 3, 4, 5, 8, 6, 7, 13, 38, 9, 12, 16, 17, 15, 10, 11, 14, 26, 28, 19, 20, 41, 22, 25, 30, 23, 47, 21, 27, 35, 31, 36, 44, 33, 42, 24, 46, 45, 37, 29, 32, 34, 43, 40, 39, ]\n",
            "[42, 0, 1, 2, 3, 6, 4, 5, 9, 7, 11, 8, 10, 12, 13, 17, 14, 16, 15, 18, 19, 22, 41, 24, 20, 23, 27, 25, 26, 35, 34, 39, 40, 32, 28, 30, 46, 29, 31, 44, 47, 43, 21, 45, 33, 36, 38, 37, ]\n",
            "[42, 0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 9, 10, 12, 17, 23, 13, 16, 14, 18, 19, 20, 25, 47, 31, 21, 22, 26, 37, 24, 38, 27, 29, 28, 35, 32, 41, 45, 40, 33, 46, 34, 15, 36, 39, 30, 43, 44, ]\n",
            "[34, 0, 1, 2, 3, 6, 4, 5, 7, 8, 9, 43, 13, 10, 12, 14, 17, 15, 16, 18, 22, 30, 19, 20, 23, 24, 44, 35, 37, 45, 25, 38, 42, 26, 11, 21, 32, 27, 39, 40, 28, 46, 31, 29, 41, 33, 47, 36, ]\n",
            "[46, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 12, 13, 16, 24, 17, 18, 43, 19, 36, 22, 20, 25, 44, 26, 32, 42, 21, 28, 45, 29, 37, 33, 34, 39, 41, 35, 40, 38, 47, 30, 27, 31, 23, ]\n",
            "[1, 42, 0, 2, 5, 3, 4, 6, 7, 8, 11, 9, 36, 10, 16, 13, 15, 14, 17, 18, 19, 22, 20, 24, 21, 23, 25, 29, 30, 39, 26, 41, 44, 31, 38, 46, 35, 45, 40, 28, 27, 34, 12, 47, 33, 43, 37, 32, ]\n",
            "[6, 0, 1, 8, 2, 4, 3, 5, 31, 7, 9, 10, 11, 12, 13, 14, 15, 16, 23, 17, 19, 20, 26, 21, 18, 22, 24, 25, 32, 37, 33, 42, 29, 35, 39, 28, 40, 27, 43, 30, 34, 45, 41, 36, 47, 44, 38, 46, ]\n",
            "[30, 0, 1, 2, 6, 3, 5, 4, 7, 8, 9, 12, 10, 11, 15, 13, 14, 16, 25, 20, 17, 19, 24, 21, 27, 42, 29, 23, 34, 28, 18, 32, 39, 45, 22, 40, 31, 26, 44, 37, 38, 36, 46, 41, 43, 47, 33, 35, ]\n",
            "[18, 0, 1, 2, 3, 4, 33, 5, 7, 8, 9, 12, 10, 11, 13, 17, 15, 14, 6, 16, 19, 20, 21, 22, 23, 47, 24, 35, 26, 37, 29, 30, 41, 43, 28, 34, 46, 27, 44, 38, 45, 40, 32, 25, 31, 39, 42, 36, ]\n",
            "[26, 0, 1, 2, 3, 4, 7, 5, 12, 6, 9, 10, 11, 8, 13, 14, 15, 16, 17, 18, 23, 24, 27, 19, 45, 20, 47, 25, 22, 41, 28, 30, 33, 35, 39, 44, 29, 42, 37, 21, 31, 46, 32, 38, 40, 36, 43, 34, ]\n",
            "[10, 0, 1, 2, 6, 41, 3, 4, 7, 12, 5, 8, 11, 9, 13, 14, 15, 16, 17, 18, 19, 23, 20, 24, 22, 26, 27, 21, 29, 31, 44, 25, 34, 35, 38, 32, 37, 45, 28, 36, 42, 30, 46, 40, 47, 33, 39, 43, ]\n",
            "[2, 0, 43, 1, 3, 4, 5, 6, 7, 8, 9, 12, 10, 16, 11, 13, 14, 15, 20, 17, 19, 18, 21, 27, 23, 22, 28, 25, 24, 35, 29, 36, 42, 39, 41, 26, 38, 32, 45, 30, 34, 37, 33, 47, 40, 46, 44, 31, ]\n",
            "[14, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 11, 38, 12, 15, 16, 19, 17, 18, 46, 20, 21, 25, 22, 29, 28, 24, 30, 27, 35, 44, 40, 31, 26, 43, 34, 47, 36, 41, 39, 23, 37, 33, 42, 32, 45, ]\n",
            "[22, 2, 0, 1, 3, 4, 5, 6, 7, 8, 11, 9, 13, 10, 15, 12, 14, 18, 16, 20, 17, 25, 45, 24, 19, 23, 27, 28, 21, 46, 33, 38, 35, 37, 42, 40, 31, 26, 30, 29, 44, 47, 32, 39, 41, 34, 36, 43, ]\n",
            "[10, 0, 1, 2, 3, 4, 5, 6, 7, 11, 13, 8, 9, 44, 15, 12, 17, 14, 20, 23, 16, 18, 21, 29, 43, 22, 45, 31, 25, 28, 19, 34, 35, 37, 30, 36, 27, 39, 42, 32, 41, 38, 46, 26, 24, 47, 33, 40, ]\n",
            "[14, 0, 1, 2, 5, 3, 4, 6, 7, 8, 9, 13, 16, 10, 44, 12, 11, 15, 17, 18, 31, 23, 21, 19, 26, 22, 25, 30, 32, 28, 24, 33, 27, 34, 29, 36, 39, 45, 47, 20, 35, 40, 43, 38, 46, 41, 42, 37, ]\n",
            "[46, 0, 1, 4, 2, 3, 5, 6, 7, 8, 11, 9, 10, 12, 13, 14, 15, 31, 19, 16, 21, 18, 20, 22, 28, 26, 23, 25, 27, 33, 29, 41, 24, 37, 39, 32, 40, 45, 34, 47, 42, 36, 43, 38, 30, 35, 17, 44, ]\n",
            "[38, 0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 9, 10, 12, 13, 14, 15, 19, 40, 16, 22, 17, 21, 28, 25, 35, 20, 33, 26, 24, 42, 43, 34, 32, 29, 23, 37, 27, 18, 47, 30, 36, 46, 45, 31, 41, 39, 44, ]\n",
            "[6, 0, 1, 2, 3, 4, 7, 44, 5, 10, 11, 8, 9, 12, 13, 14, 15, 18, 16, 20, 17, 46, 19, 25, 23, 22, 27, 33, 39, 24, 29, 42, 28, 35, 41, 38, 21, 26, 30, 37, 45, 47, 34, 31, 36, 32, 43, 40, ]\n",
            "[30, 0, 1, 2, 3, 4, 5, 8, 6, 10, 7, 15, 11, 9, 17, 13, 12, 16, 14, 20, 18, 37, 19, 22, 25, 32, 23, 33, 26, 24, 31, 34, 28, 35, 41, 39, 29, 40, 45, 38, 46, 21, 44, 42, 27, 36, 47, 43, ]\n",
            "[18, 0, 39, 1, 3, 6, 4, 5, 7, 8, 9, 10, 14, 15, 11, 12, 13, 16, 2, 21, 38, 17, 19, 22, 30, 32, 25, 28, 23, 41, 27, 46, 24, 42, 40, 20, 29, 45, 33, 36, 26, 35, 31, 34, 43, 44, 47, 37, ]\n",
            "[38, 0, 1, 2, 3, 4, 5, 8, 6, 10, 7, 9, 11, 12, 13, 14, 17, 15, 21, 16, 19, 20, 23, 18, 26, 37, 22, 29, 27, 34, 42, 24, 30, 39, 47, 36, 31, 35, 33, 28, 32, 43, 25, 44, 40, 46, 41, 45, ]\n",
            "[42, 0, 1, 2, 3, 4, 5, 6, 7, 13, 8, 12, 14, 40, 10, 11, 15, 16, 17, 20, 18, 35, 38, 19, 25, 23, 24, 26, 30, 47, 27, 28, 36, 31, 44, 39, 33, 43, 41, 37, 22, 29, 9, 32, 21, 46, 34, 45, ]\n",
            "[34, 0, 1, 2, 3, 4, 5, 37, 6, 8, 11, 9, 10, 12, 15, 13, 14, 18, 16, 17, 19, 23, 20, 24, 22, 27, 29, 21, 30, 28, 36, 42, 41, 38, 7, 26, 25, 31, 40, 47, 35, 33, 39, 44, 32, 46, 43, 45, ]\n",
            "[30, 0, 1, 2, 3, 4, 5, 6, 9, 11, 8, 7, 10, 12, 13, 14, 18, 15, 17, 20, 16, 24, 19, 25, 22, 26, 21, 32, 23, 28, 46, 38, 29, 34, 27, 41, 42, 43, 33, 31, 37, 40, 45, 44, 47, 39, 35, 36, ]\n",
            "[42, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 13, 14, 18, 16, 20, 17, 19, 23, 21, 22, 28, 27, 24, 26, 32, 47, 25, 33, 31, 38, 45, 29, 41, 30, 43, 39, 35, 34, 36, 46, 40, 37, 44, ]\n",
            "[10, 0, 1, 2, 5, 3, 4, 6, 7, 8, 30, 9, 11, 12, 16, 21, 13, 18, 14, 20, 23, 17, 15, 22, 32, 29, 46, 31, 33, 19, 34, 35, 25, 41, 26, 24, 40, 27, 37, 42, 45, 47, 43, 28, 36, 39, 44, 38, ]\n",
            "[2, 0, 33, 1, 3, 4, 5, 6, 9, 7, 8, 10, 11, 12, 46, 13, 15, 16, 19, 17, 22, 25, 18, 20, 23, 26, 24, 28, 21, 34, 29, 30, 44, 14, 27, 45, 41, 39, 47, 40, 38, 31, 37, 42, 35, 43, 32, 36, ]\n",
            "[14, 0, 1, 2, 3, 4, 5, 6, 9, 7, 32, 12, 8, 11, 41, 18, 45, 15, 13, 21, 17, 20, 29, 24, 19, 23, 28, 30, 22, 25, 38, 26, 16, 31, 36, 33, 35, 34, 43, 42, 39, 10, 37, 46, 27, 44, 47, 40, ]\n",
            "]\n",
            "GPU\t\t0 sec. 591 msec.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DEV"
      ],
      "metadata": {
        "id": "kPToz950sd-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prefix Sum"
      ],
      "metadata": {
        "id": "m-MkUntOskIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name gems.cu \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define DIV_ROUNDUP(NUM,DEN) ((NUM +(DEN-1))/DEN)\n",
        "\n",
        "typedef enum { SCAN_INCLUSIVE, SCAN_EXCLUSIVE } PRESCAN_TYPE_ENUM;\n",
        "\n",
        "#define CHECK(call)                                                            \\\n",
        "{                                                                              \\\n",
        "    const cudaError_t error = call;                                            \\\n",
        "    if (error != cudaSuccess)                                                  \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
        "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
        "                cudaGetErrorString(error));                                    \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "inline double seconds() {\n",
        "    struct timeval tp;\n",
        "    struct timezone tzp;\n",
        "    int i = gettimeofday(&tp, &tzp);\n",
        "    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n",
        "}\n",
        "\n",
        "/*\n",
        "Having N elements, call with N/B blocks each of B/2 threads and allocate sizeof(float)*((N/B)+1) shared memory\n",
        "*/\n",
        "__global__ void custom_prescan(float *data, int n, float *intermediateSum, const PRESCAN_TYPE_ENUM SCAN_TYPE, const int bound) \n",
        "{ \n",
        "  extern __shared__ float temp[];\n",
        "  \n",
        "  int thid = threadIdx.x;\n",
        "  int gtid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int offset = 1;\n",
        "  \n",
        "  /* Load input into shared memory. Threads that exceed the actual array size\n",
        "  *  are zeroed out so they do not influence the correct scan result.\n",
        "  */\n",
        "  temp[2*thid] = 0;\n",
        "  temp[2*thid+1] = 0;\n",
        "  if(2*gtid < bound)\n",
        "    temp[2*thid] = data[2*gtid]; \n",
        "  if(2*gtid +1 < bound)\n",
        "    temp[2*thid+1] = data[2*gtid+1];\n",
        "  \n",
        "  \n",
        "  // build sum in place up the tree\n",
        "  for (int d = n>>1; d > 0; d >>= 1) {\n",
        "    __syncthreads();\n",
        "\n",
        "    if (thid < d) { \n",
        "      int ai = offset*(2*thid+1)-1;     \n",
        "      int bi = offset*(2*thid+2)-1;  \n",
        "      temp[bi] += temp[ai];    \n",
        "    }\n",
        "    offset *= 2; \n",
        "  }\n",
        "\n",
        "  if (thid == 0) { \n",
        "    if(intermediateSum!=NULL)\n",
        "      intermediateSum[blockIdx.x] = temp[n-1];\n",
        "    \n",
        "    if(SCAN_TYPE==SCAN_INCLUSIVE)\n",
        "      temp[n] = temp[n-1];\n",
        "\n",
        "    temp[n-1] = 0.0f;\n",
        "  }\n",
        "\n",
        "  // traverse down tree & build scan \n",
        "  for (int d = 1; d < n; d *= 2) {      \n",
        "    offset >>= 1;\n",
        "    __syncthreads();\n",
        "    if (thid < d) {\n",
        "      int ai = offset*(2*thid+1)-1;\n",
        "      int bi = offset*(2*thid+2)-1;\n",
        "      float t = temp[ai]; temp[ai] = temp[bi]; temp[bi] += t;\n",
        "    }\n",
        "  }\n",
        "  \n",
        "  __syncthreads();\n",
        "\n",
        "  int shift=0;\n",
        "  if(SCAN_TYPE==SCAN_INCLUSIVE)\n",
        "    shift =1;\n",
        "\n",
        "  if(2*gtid < bound)\n",
        "    data[2*gtid] = temp[2*thid+shift];\n",
        "  if(2*gtid +1 < bound)\n",
        "    data[2*gtid+1] = temp[2*thid+1+shift];\n",
        "  \n",
        "} \n",
        "\n",
        "__global__ void apply_increment(float *cumsum, float *increment, const int n){\n",
        "  int gidx = blockIdx.x*blockDim.x +threadIdx.x;\n",
        "\n",
        "  if(gidx < n)\n",
        "    cumsum[gidx] += increment[blockIdx.x];\n",
        "}\n",
        "\n",
        "__global__ void apply_mask(float *data, bool *mask, const int n){\n",
        "    int gtid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (gtid<n)\n",
        "      data[gtid] *= mask[gtid];\n",
        "}\n",
        "\n",
        "int closest_multiple_of(int numToRound, int multiple){\n",
        "  assert(numToRound >0);\n",
        "\n",
        "  if (multiple == 0)\n",
        "    return numToRound;\n",
        "\n",
        "  int remainder = numToRound % multiple;\n",
        "  if (remainder == 0)\n",
        "    return numToRound;\n",
        "\n",
        "  return numToRound + multiple - remainder;\n",
        "}\n",
        "\n",
        "int next_power_of_two(int n){\n",
        "    int res=1;\n",
        "    while(res<n) {res <<= 1;}\n",
        "    return res;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  int blockSize = 128;\n",
        "  int N = (2<<10) +1;\n",
        "\n",
        "  /* host side with the original size */\n",
        "  float h_v[N];\n",
        "  for(int i=0; i<N;i++) h_v[i] = 1;\n",
        "  bool h_mask[N];\n",
        "  for(int i=0; i<N;i++) h_mask[i] = true;\n",
        "  \n",
        "  int numBlocks = N/blockSize;\n",
        "  if(N%blockSize != 0)\n",
        "      numBlocks++;\n",
        "  int threadsPerBlock = blockSize/2;\n",
        "  printf(\"ARRAY OF SIZE %d BLOCKSIZE %d\\n\", N, blockSize);\n",
        "  printf(\"USING %d BLOCKS OF %d THREADS FOR PRESCAN\\n\", numBlocks, threadsPerBlock);\n",
        "\n",
        "\tfloat *d_v, *d_intermediary_sums;\n",
        "\tCHECK(cudaMalloc((void **)&d_v, sizeof(float)*N));\n",
        "  CHECK(cudaMalloc((void **)&d_intermediary_sums, sizeof(float)*numBlocks));\n",
        "\n",
        "  bool *mask;\n",
        "  CHECK(cudaMalloc((void **)&mask, sizeof(bool)*N));\n",
        "\n",
        "\n",
        "  CHECK(cudaMemcpy(d_v, h_v, sizeof(float)*N, cudaMemcpyHostToDevice));\n",
        "  CHECK(cudaMemcpy(mask, h_mask, sizeof(bool)*N, cudaMemcpyHostToDevice));\n",
        "\n",
        "  apply_mask<<<numBlocks, threadsPerBlock>>>(d_v, mask, N);\n",
        "  custom_prescan<<<numBlocks, threadsPerBlock, sizeof(float)*(blockSize+1)>>>(d_v, blockSize, d_intermediary_sums, SCAN_INCLUSIVE, N);  \n",
        "  if(numBlocks>1){\n",
        "    printf(\"\\n\\nlaunching 1 block of %d threads with %d floats of shared memory to process %d elem\\n\" ,threadsPerBlock, threadsPerBlock*2, numBlocks);\n",
        "    \n",
        "    custom_prescan<<<1, threadsPerBlock, sizeof(float)*threadsPerBlock*2>>> (d_intermediary_sums, threadsPerBlock, NULL, SCAN_EXCLUSIVE, numBlocks);     \n",
        "    apply_increment<<<numBlocks, threadsPerBlock*2>>>(d_v, d_intermediary_sums, N);\n",
        "  }\n",
        "\n",
        "\tCHECK(cudaMemcpy(h_v, d_v, sizeof(float)*N, cudaMemcpyDeviceToHost));\n",
        "  for(int i=0; i<N; i++) printf(\"%f \", h_v[i]);\n",
        "\n",
        "  CHECK(cudaFree(d_v));\n",
        "\n",
        "  CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "  float test[N];\n",
        "  test[0] = 1;\n",
        "  for(int i=1; i<N; i++) test[i] = 1 + test[i-1];\n",
        "\n",
        "  for(int i=0; i<N; i++){\n",
        "    if(fabs(h_v[i]-test[i]) > 0.01){\n",
        "      printf(\"i %d gpu %f, cpu %f\\n\", i, h_v[i], test[i]);\n",
        "      return -1;\n",
        "    } \n",
        "  }\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uD6ygRElLqQM",
        "outputId": "766a273b-ca8b-4b3c-fd70-c6b4f9c058e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/gems.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -g -G src/gems.cu -o example\n",
        "!./example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty1J2Q-VRzWH",
        "outputId": "aef501d8-e8a5-46c8-e251-d0b6d8afcd50"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARRAY OF SIZE 2049 BLOCKSIZE 128\n",
            "USING 17 BLOCKS OF 64 THREADS FOR PRESCAN\n",
            "\n",
            "\n",
            "launching 1 block of 64 threads with 128 floats of shared memory to process 17 elem\n",
            "1.000000 2.000000 3.000000 4.000000 5.000000 6.000000 7.000000 8.000000 9.000000 10.000000 11.000000 12.000000 13.000000 14.000000 15.000000 16.000000 17.000000 18.000000 19.000000 20.000000 21.000000 22.000000 23.000000 24.000000 25.000000 26.000000 27.000000 28.000000 29.000000 30.000000 31.000000 32.000000 33.000000 34.000000 35.000000 36.000000 37.000000 38.000000 39.000000 40.000000 41.000000 42.000000 43.000000 44.000000 45.000000 46.000000 47.000000 48.000000 49.000000 50.000000 51.000000 52.000000 53.000000 54.000000 55.000000 56.000000 57.000000 58.000000 59.000000 60.000000 61.000000 62.000000 63.000000 64.000000 65.000000 66.000000 67.000000 68.000000 69.000000 70.000000 71.000000 72.000000 73.000000 74.000000 75.000000 76.000000 77.000000 78.000000 79.000000 80.000000 81.000000 82.000000 83.000000 84.000000 85.000000 86.000000 87.000000 88.000000 89.000000 90.000000 91.000000 92.000000 93.000000 94.000000 95.000000 96.000000 97.000000 98.000000 99.000000 100.000000 101.000000 102.000000 103.000000 104.000000 105.000000 106.000000 107.000000 108.000000 109.000000 110.000000 111.000000 112.000000 113.000000 114.000000 115.000000 116.000000 117.000000 118.000000 119.000000 120.000000 121.000000 122.000000 123.000000 124.000000 125.000000 126.000000 127.000000 128.000000 129.000000 130.000000 131.000000 132.000000 133.000000 134.000000 135.000000 136.000000 137.000000 138.000000 139.000000 140.000000 141.000000 142.000000 143.000000 144.000000 145.000000 146.000000 147.000000 148.000000 149.000000 150.000000 151.000000 152.000000 153.000000 154.000000 155.000000 156.000000 157.000000 158.000000 159.000000 160.000000 161.000000 162.000000 163.000000 164.000000 165.000000 166.000000 167.000000 168.000000 169.000000 170.000000 171.000000 172.000000 173.000000 174.000000 175.000000 176.000000 177.000000 178.000000 179.000000 180.000000 181.000000 182.000000 183.000000 184.000000 185.000000 186.000000 187.000000 188.000000 189.000000 190.000000 191.000000 192.000000 193.000000 194.000000 195.000000 196.000000 197.000000 198.000000 199.000000 200.000000 201.000000 202.000000 203.000000 204.000000 205.000000 206.000000 207.000000 208.000000 209.000000 210.000000 211.000000 212.000000 213.000000 214.000000 215.000000 216.000000 217.000000 218.000000 219.000000 220.000000 221.000000 222.000000 223.000000 224.000000 225.000000 226.000000 227.000000 228.000000 229.000000 230.000000 231.000000 232.000000 233.000000 234.000000 235.000000 236.000000 237.000000 238.000000 239.000000 240.000000 241.000000 242.000000 243.000000 244.000000 245.000000 246.000000 247.000000 248.000000 249.000000 250.000000 251.000000 252.000000 253.000000 254.000000 255.000000 256.000000 257.000000 258.000000 259.000000 260.000000 261.000000 262.000000 263.000000 264.000000 265.000000 266.000000 267.000000 268.000000 269.000000 270.000000 271.000000 272.000000 273.000000 274.000000 275.000000 276.000000 277.000000 278.000000 279.000000 280.000000 281.000000 282.000000 283.000000 284.000000 285.000000 286.000000 287.000000 288.000000 289.000000 290.000000 291.000000 292.000000 293.000000 294.000000 295.000000 296.000000 297.000000 298.000000 299.000000 300.000000 301.000000 302.000000 303.000000 304.000000 305.000000 306.000000 307.000000 308.000000 309.000000 310.000000 311.000000 312.000000 313.000000 314.000000 315.000000 316.000000 317.000000 318.000000 319.000000 320.000000 321.000000 322.000000 323.000000 324.000000 325.000000 326.000000 327.000000 328.000000 329.000000 330.000000 331.000000 332.000000 333.000000 334.000000 335.000000 336.000000 337.000000 338.000000 339.000000 340.000000 341.000000 342.000000 343.000000 344.000000 345.000000 346.000000 347.000000 348.000000 349.000000 350.000000 351.000000 352.000000 353.000000 354.000000 355.000000 356.000000 357.000000 358.000000 359.000000 360.000000 361.000000 362.000000 363.000000 364.000000 365.000000 366.000000 367.000000 368.000000 369.000000 370.000000 371.000000 372.000000 373.000000 374.000000 375.000000 376.000000 377.000000 378.000000 379.000000 380.000000 381.000000 382.000000 383.000000 384.000000 385.000000 386.000000 387.000000 388.000000 389.000000 390.000000 391.000000 392.000000 393.000000 394.000000 395.000000 396.000000 397.000000 398.000000 399.000000 400.000000 401.000000 402.000000 403.000000 404.000000 405.000000 406.000000 407.000000 408.000000 409.000000 410.000000 411.000000 412.000000 413.000000 414.000000 415.000000 416.000000 417.000000 418.000000 419.000000 420.000000 421.000000 422.000000 423.000000 424.000000 425.000000 426.000000 427.000000 428.000000 429.000000 430.000000 431.000000 432.000000 433.000000 434.000000 435.000000 436.000000 437.000000 438.000000 439.000000 440.000000 441.000000 442.000000 443.000000 444.000000 445.000000 446.000000 447.000000 448.000000 449.000000 450.000000 451.000000 452.000000 453.000000 454.000000 455.000000 456.000000 457.000000 458.000000 459.000000 460.000000 461.000000 462.000000 463.000000 464.000000 465.000000 466.000000 467.000000 468.000000 469.000000 470.000000 471.000000 472.000000 473.000000 474.000000 475.000000 476.000000 477.000000 478.000000 479.000000 480.000000 481.000000 482.000000 483.000000 484.000000 485.000000 486.000000 487.000000 488.000000 489.000000 490.000000 491.000000 492.000000 493.000000 494.000000 495.000000 496.000000 497.000000 498.000000 499.000000 500.000000 501.000000 502.000000 503.000000 504.000000 505.000000 506.000000 507.000000 508.000000 509.000000 510.000000 511.000000 512.000000 513.000000 514.000000 515.000000 516.000000 517.000000 518.000000 519.000000 520.000000 521.000000 522.000000 523.000000 524.000000 525.000000 526.000000 527.000000 528.000000 529.000000 530.000000 531.000000 532.000000 533.000000 534.000000 535.000000 536.000000 537.000000 538.000000 539.000000 540.000000 541.000000 542.000000 543.000000 544.000000 545.000000 546.000000 547.000000 548.000000 549.000000 550.000000 551.000000 552.000000 553.000000 554.000000 555.000000 556.000000 557.000000 558.000000 559.000000 560.000000 561.000000 562.000000 563.000000 564.000000 565.000000 566.000000 567.000000 568.000000 569.000000 570.000000 571.000000 572.000000 573.000000 574.000000 575.000000 576.000000 577.000000 578.000000 579.000000 580.000000 581.000000 582.000000 583.000000 584.000000 585.000000 586.000000 587.000000 588.000000 589.000000 590.000000 591.000000 592.000000 593.000000 594.000000 595.000000 596.000000 597.000000 598.000000 599.000000 600.000000 601.000000 602.000000 603.000000 604.000000 605.000000 606.000000 607.000000 608.000000 609.000000 610.000000 611.000000 612.000000 613.000000 614.000000 615.000000 616.000000 617.000000 618.000000 619.000000 620.000000 621.000000 622.000000 623.000000 624.000000 625.000000 626.000000 627.000000 628.000000 629.000000 630.000000 631.000000 632.000000 633.000000 634.000000 635.000000 636.000000 637.000000 638.000000 639.000000 640.000000 641.000000 642.000000 643.000000 644.000000 645.000000 646.000000 647.000000 648.000000 649.000000 650.000000 651.000000 652.000000 653.000000 654.000000 655.000000 656.000000 657.000000 658.000000 659.000000 660.000000 661.000000 662.000000 663.000000 664.000000 665.000000 666.000000 667.000000 668.000000 669.000000 670.000000 671.000000 672.000000 673.000000 674.000000 675.000000 676.000000 677.000000 678.000000 679.000000 680.000000 681.000000 682.000000 683.000000 684.000000 685.000000 686.000000 687.000000 688.000000 689.000000 690.000000 691.000000 692.000000 693.000000 694.000000 695.000000 696.000000 697.000000 698.000000 699.000000 700.000000 701.000000 702.000000 703.000000 704.000000 705.000000 706.000000 707.000000 708.000000 709.000000 710.000000 711.000000 712.000000 713.000000 714.000000 715.000000 716.000000 717.000000 718.000000 719.000000 720.000000 721.000000 722.000000 723.000000 724.000000 725.000000 726.000000 727.000000 728.000000 729.000000 730.000000 731.000000 732.000000 733.000000 734.000000 735.000000 736.000000 737.000000 738.000000 739.000000 740.000000 741.000000 742.000000 743.000000 744.000000 745.000000 746.000000 747.000000 748.000000 749.000000 750.000000 751.000000 752.000000 753.000000 754.000000 755.000000 756.000000 757.000000 758.000000 759.000000 760.000000 761.000000 762.000000 763.000000 764.000000 765.000000 766.000000 767.000000 768.000000 769.000000 770.000000 771.000000 772.000000 773.000000 774.000000 775.000000 776.000000 777.000000 778.000000 779.000000 780.000000 781.000000 782.000000 783.000000 784.000000 785.000000 786.000000 787.000000 788.000000 789.000000 790.000000 791.000000 792.000000 793.000000 794.000000 795.000000 796.000000 797.000000 798.000000 799.000000 800.000000 801.000000 802.000000 803.000000 804.000000 805.000000 806.000000 807.000000 808.000000 809.000000 810.000000 811.000000 812.000000 813.000000 814.000000 815.000000 816.000000 817.000000 818.000000 819.000000 820.000000 821.000000 822.000000 823.000000 824.000000 825.000000 826.000000 827.000000 828.000000 829.000000 830.000000 831.000000 832.000000 833.000000 834.000000 835.000000 836.000000 837.000000 838.000000 839.000000 840.000000 841.000000 842.000000 843.000000 844.000000 845.000000 846.000000 847.000000 848.000000 849.000000 850.000000 851.000000 852.000000 853.000000 854.000000 855.000000 856.000000 857.000000 858.000000 859.000000 860.000000 861.000000 862.000000 863.000000 864.000000 865.000000 866.000000 867.000000 868.000000 869.000000 870.000000 871.000000 872.000000 873.000000 874.000000 875.000000 876.000000 877.000000 878.000000 879.000000 880.000000 881.000000 882.000000 883.000000 884.000000 885.000000 886.000000 887.000000 888.000000 889.000000 890.000000 891.000000 892.000000 893.000000 894.000000 895.000000 896.000000 897.000000 898.000000 899.000000 900.000000 901.000000 902.000000 903.000000 904.000000 905.000000 906.000000 907.000000 908.000000 909.000000 910.000000 911.000000 912.000000 913.000000 914.000000 915.000000 916.000000 917.000000 918.000000 919.000000 920.000000 921.000000 922.000000 923.000000 924.000000 925.000000 926.000000 927.000000 928.000000 929.000000 930.000000 931.000000 932.000000 933.000000 934.000000 935.000000 936.000000 937.000000 938.000000 939.000000 940.000000 941.000000 942.000000 943.000000 944.000000 945.000000 946.000000 947.000000 948.000000 949.000000 950.000000 951.000000 952.000000 953.000000 954.000000 955.000000 956.000000 957.000000 958.000000 959.000000 960.000000 961.000000 962.000000 963.000000 964.000000 965.000000 966.000000 967.000000 968.000000 969.000000 970.000000 971.000000 972.000000 973.000000 974.000000 975.000000 976.000000 977.000000 978.000000 979.000000 980.000000 981.000000 982.000000 983.000000 984.000000 985.000000 986.000000 987.000000 988.000000 989.000000 990.000000 991.000000 992.000000 993.000000 994.000000 995.000000 996.000000 997.000000 998.000000 999.000000 1000.000000 1001.000000 1002.000000 1003.000000 1004.000000 1005.000000 1006.000000 1007.000000 1008.000000 1009.000000 1010.000000 1011.000000 1012.000000 1013.000000 1014.000000 1015.000000 1016.000000 1017.000000 1018.000000 1019.000000 1020.000000 1021.000000 1022.000000 1023.000000 1024.000000 1025.000000 1026.000000 1027.000000 1028.000000 1029.000000 1030.000000 1031.000000 1032.000000 1033.000000 1034.000000 1035.000000 1036.000000 1037.000000 1038.000000 1039.000000 1040.000000 1041.000000 1042.000000 1043.000000 1044.000000 1045.000000 1046.000000 1047.000000 1048.000000 1049.000000 1050.000000 1051.000000 1052.000000 1053.000000 1054.000000 1055.000000 1056.000000 1057.000000 1058.000000 1059.000000 1060.000000 1061.000000 1062.000000 1063.000000 1064.000000 1065.000000 1066.000000 1067.000000 1068.000000 1069.000000 1070.000000 1071.000000 1072.000000 1073.000000 1074.000000 1075.000000 1076.000000 1077.000000 1078.000000 1079.000000 1080.000000 1081.000000 1082.000000 1083.000000 1084.000000 1085.000000 1086.000000 1087.000000 1088.000000 1089.000000 1090.000000 1091.000000 1092.000000 1093.000000 1094.000000 1095.000000 1096.000000 1097.000000 1098.000000 1099.000000 1100.000000 1101.000000 1102.000000 1103.000000 1104.000000 1105.000000 1106.000000 1107.000000 1108.000000 1109.000000 1110.000000 1111.000000 1112.000000 1113.000000 1114.000000 1115.000000 1116.000000 1117.000000 1118.000000 1119.000000 1120.000000 1121.000000 1122.000000 1123.000000 1124.000000 1125.000000 1126.000000 1127.000000 1128.000000 1129.000000 1130.000000 1131.000000 1132.000000 1133.000000 1134.000000 1135.000000 1136.000000 1137.000000 1138.000000 1139.000000 1140.000000 1141.000000 1142.000000 1143.000000 1144.000000 1145.000000 1146.000000 1147.000000 1148.000000 1149.000000 1150.000000 1151.000000 1152.000000 1153.000000 1154.000000 1155.000000 1156.000000 1157.000000 1158.000000 1159.000000 1160.000000 1161.000000 1162.000000 1163.000000 1164.000000 1165.000000 1166.000000 1167.000000 1168.000000 1169.000000 1170.000000 1171.000000 1172.000000 1173.000000 1174.000000 1175.000000 1176.000000 1177.000000 1178.000000 1179.000000 1180.000000 1181.000000 1182.000000 1183.000000 1184.000000 1185.000000 1186.000000 1187.000000 1188.000000 1189.000000 1190.000000 1191.000000 1192.000000 1193.000000 1194.000000 1195.000000 1196.000000 1197.000000 1198.000000 1199.000000 1200.000000 1201.000000 1202.000000 1203.000000 1204.000000 1205.000000 1206.000000 1207.000000 1208.000000 1209.000000 1210.000000 1211.000000 1212.000000 1213.000000 1214.000000 1215.000000 1216.000000 1217.000000 1218.000000 1219.000000 1220.000000 1221.000000 1222.000000 1223.000000 1224.000000 1225.000000 1226.000000 1227.000000 1228.000000 1229.000000 1230.000000 1231.000000 1232.000000 1233.000000 1234.000000 1235.000000 1236.000000 1237.000000 1238.000000 1239.000000 1240.000000 1241.000000 1242.000000 1243.000000 1244.000000 1245.000000 1246.000000 1247.000000 1248.000000 1249.000000 1250.000000 1251.000000 1252.000000 1253.000000 1254.000000 1255.000000 1256.000000 1257.000000 1258.000000 1259.000000 1260.000000 1261.000000 1262.000000 1263.000000 1264.000000 1265.000000 1266.000000 1267.000000 1268.000000 1269.000000 1270.000000 1271.000000 1272.000000 1273.000000 1274.000000 1275.000000 1276.000000 1277.000000 1278.000000 1279.000000 1280.000000 1281.000000 1282.000000 1283.000000 1284.000000 1285.000000 1286.000000 1287.000000 1288.000000 1289.000000 1290.000000 1291.000000 1292.000000 1293.000000 1294.000000 1295.000000 1296.000000 1297.000000 1298.000000 1299.000000 1300.000000 1301.000000 1302.000000 1303.000000 1304.000000 1305.000000 1306.000000 1307.000000 1308.000000 1309.000000 1310.000000 1311.000000 1312.000000 1313.000000 1314.000000 1315.000000 1316.000000 1317.000000 1318.000000 1319.000000 1320.000000 1321.000000 1322.000000 1323.000000 1324.000000 1325.000000 1326.000000 1327.000000 1328.000000 1329.000000 1330.000000 1331.000000 1332.000000 1333.000000 1334.000000 1335.000000 1336.000000 1337.000000 1338.000000 1339.000000 1340.000000 1341.000000 1342.000000 1343.000000 1344.000000 1345.000000 1346.000000 1347.000000 1348.000000 1349.000000 1350.000000 1351.000000 1352.000000 1353.000000 1354.000000 1355.000000 1356.000000 1357.000000 1358.000000 1359.000000 1360.000000 1361.000000 1362.000000 1363.000000 1364.000000 1365.000000 1366.000000 1367.000000 1368.000000 1369.000000 1370.000000 1371.000000 1372.000000 1373.000000 1374.000000 1375.000000 1376.000000 1377.000000 1378.000000 1379.000000 1380.000000 1381.000000 1382.000000 1383.000000 1384.000000 1385.000000 1386.000000 1387.000000 1388.000000 1389.000000 1390.000000 1391.000000 1392.000000 1393.000000 1394.000000 1395.000000 1396.000000 1397.000000 1398.000000 1399.000000 1400.000000 1401.000000 1402.000000 1403.000000 1404.000000 1405.000000 1406.000000 1407.000000 1408.000000 1409.000000 1410.000000 1411.000000 1412.000000 1413.000000 1414.000000 1415.000000 1416.000000 1417.000000 1418.000000 1419.000000 1420.000000 1421.000000 1422.000000 1423.000000 1424.000000 1425.000000 1426.000000 1427.000000 1428.000000 1429.000000 1430.000000 1431.000000 1432.000000 1433.000000 1434.000000 1435.000000 1436.000000 1437.000000 1438.000000 1439.000000 1440.000000 1441.000000 1442.000000 1443.000000 1444.000000 1445.000000 1446.000000 1447.000000 1448.000000 1449.000000 1450.000000 1451.000000 1452.000000 1453.000000 1454.000000 1455.000000 1456.000000 1457.000000 1458.000000 1459.000000 1460.000000 1461.000000 1462.000000 1463.000000 1464.000000 1465.000000 1466.000000 1467.000000 1468.000000 1469.000000 1470.000000 1471.000000 1472.000000 1473.000000 1474.000000 1475.000000 1476.000000 1477.000000 1478.000000 1479.000000 1480.000000 1481.000000 1482.000000 1483.000000 1484.000000 1485.000000 1486.000000 1487.000000 1488.000000 1489.000000 1490.000000 1491.000000 1492.000000 1493.000000 1494.000000 1495.000000 1496.000000 1497.000000 1498.000000 1499.000000 1500.000000 1501.000000 1502.000000 1503.000000 1504.000000 1505.000000 1506.000000 1507.000000 1508.000000 1509.000000 1510.000000 1511.000000 1512.000000 1513.000000 1514.000000 1515.000000 1516.000000 1517.000000 1518.000000 1519.000000 1520.000000 1521.000000 1522.000000 1523.000000 1524.000000 1525.000000 1526.000000 1527.000000 1528.000000 1529.000000 1530.000000 1531.000000 1532.000000 1533.000000 1534.000000 1535.000000 1536.000000 1537.000000 1538.000000 1539.000000 1540.000000 1541.000000 1542.000000 1543.000000 1544.000000 1545.000000 1546.000000 1547.000000 1548.000000 1549.000000 1550.000000 1551.000000 1552.000000 1553.000000 1554.000000 1555.000000 1556.000000 1557.000000 1558.000000 1559.000000 1560.000000 1561.000000 1562.000000 1563.000000 1564.000000 1565.000000 1566.000000 1567.000000 1568.000000 1569.000000 1570.000000 1571.000000 1572.000000 1573.000000 1574.000000 1575.000000 1576.000000 1577.000000 1578.000000 1579.000000 1580.000000 1581.000000 1582.000000 1583.000000 1584.000000 1585.000000 1586.000000 1587.000000 1588.000000 1589.000000 1590.000000 1591.000000 1592.000000 1593.000000 1594.000000 1595.000000 1596.000000 1597.000000 1598.000000 1599.000000 1600.000000 1601.000000 1602.000000 1603.000000 1604.000000 1605.000000 1606.000000 1607.000000 1608.000000 1609.000000 1610.000000 1611.000000 1612.000000 1613.000000 1614.000000 1615.000000 1616.000000 1617.000000 1618.000000 1619.000000 1620.000000 1621.000000 1622.000000 1623.000000 1624.000000 1625.000000 1626.000000 1627.000000 1628.000000 1629.000000 1630.000000 1631.000000 1632.000000 1633.000000 1634.000000 1635.000000 1636.000000 1637.000000 1638.000000 1639.000000 1640.000000 1641.000000 1642.000000 1643.000000 1644.000000 1645.000000 1646.000000 1647.000000 1648.000000 1649.000000 1650.000000 1651.000000 1652.000000 1653.000000 1654.000000 1655.000000 1656.000000 1657.000000 1658.000000 1659.000000 1660.000000 1661.000000 1662.000000 1663.000000 1664.000000 1665.000000 1666.000000 1667.000000 1668.000000 1669.000000 1670.000000 1671.000000 1672.000000 1673.000000 1674.000000 1675.000000 1676.000000 1677.000000 1678.000000 1679.000000 1680.000000 1681.000000 1682.000000 1683.000000 1684.000000 1685.000000 1686.000000 1687.000000 1688.000000 1689.000000 1690.000000 1691.000000 1692.000000 1693.000000 1694.000000 1695.000000 1696.000000 1697.000000 1698.000000 1699.000000 1700.000000 1701.000000 1702.000000 1703.000000 1704.000000 1705.000000 1706.000000 1707.000000 1708.000000 1709.000000 1710.000000 1711.000000 1712.000000 1713.000000 1714.000000 1715.000000 1716.000000 1717.000000 1718.000000 1719.000000 1720.000000 1721.000000 1722.000000 1723.000000 1724.000000 1725.000000 1726.000000 1727.000000 1728.000000 1729.000000 1730.000000 1731.000000 1732.000000 1733.000000 1734.000000 1735.000000 1736.000000 1737.000000 1738.000000 1739.000000 1740.000000 1741.000000 1742.000000 1743.000000 1744.000000 1745.000000 1746.000000 1747.000000 1748.000000 1749.000000 1750.000000 1751.000000 1752.000000 1753.000000 1754.000000 1755.000000 1756.000000 1757.000000 1758.000000 1759.000000 1760.000000 1761.000000 1762.000000 1763.000000 1764.000000 1765.000000 1766.000000 1767.000000 1768.000000 1769.000000 1770.000000 1771.000000 1772.000000 1773.000000 1774.000000 1775.000000 1776.000000 1777.000000 1778.000000 1779.000000 1780.000000 1781.000000 1782.000000 1783.000000 1784.000000 1785.000000 1786.000000 1787.000000 1788.000000 1789.000000 1790.000000 1791.000000 1792.000000 1793.000000 1794.000000 1795.000000 1796.000000 1797.000000 1798.000000 1799.000000 1800.000000 1801.000000 1802.000000 1803.000000 1804.000000 1805.000000 1806.000000 1807.000000 1808.000000 1809.000000 1810.000000 1811.000000 1812.000000 1813.000000 1814.000000 1815.000000 1816.000000 1817.000000 1818.000000 1819.000000 1820.000000 1821.000000 1822.000000 1823.000000 1824.000000 1825.000000 1826.000000 1827.000000 1828.000000 1829.000000 1830.000000 1831.000000 1832.000000 1833.000000 1834.000000 1835.000000 1836.000000 1837.000000 1838.000000 1839.000000 1840.000000 1841.000000 1842.000000 1843.000000 1844.000000 1845.000000 1846.000000 1847.000000 1848.000000 1849.000000 1850.000000 1851.000000 1852.000000 1853.000000 1854.000000 1855.000000 1856.000000 1857.000000 1858.000000 1859.000000 1860.000000 1861.000000 1862.000000 1863.000000 1864.000000 1865.000000 1866.000000 1867.000000 1868.000000 1869.000000 1870.000000 1871.000000 1872.000000 1873.000000 1874.000000 1875.000000 1876.000000 1877.000000 1878.000000 1879.000000 1880.000000 1881.000000 1882.000000 1883.000000 1884.000000 1885.000000 1886.000000 1887.000000 1888.000000 1889.000000 1890.000000 1891.000000 1892.000000 1893.000000 1894.000000 1895.000000 1896.000000 1897.000000 1898.000000 1899.000000 1900.000000 1901.000000 1902.000000 1903.000000 1904.000000 1905.000000 1906.000000 1907.000000 1908.000000 1909.000000 1910.000000 1911.000000 1912.000000 1913.000000 1914.000000 1915.000000 1916.000000 1917.000000 1918.000000 1919.000000 1920.000000 1921.000000 1922.000000 1923.000000 1924.000000 1925.000000 1926.000000 1927.000000 1928.000000 1929.000000 1930.000000 1931.000000 1932.000000 1933.000000 1934.000000 1935.000000 1936.000000 1937.000000 1938.000000 1939.000000 1940.000000 1941.000000 1942.000000 1943.000000 1944.000000 1945.000000 1946.000000 1947.000000 1948.000000 1949.000000 1950.000000 1951.000000 1952.000000 1953.000000 1954.000000 1955.000000 1956.000000 1957.000000 1958.000000 1959.000000 1960.000000 1961.000000 1962.000000 1963.000000 1964.000000 1965.000000 1966.000000 1967.000000 1968.000000 1969.000000 1970.000000 1971.000000 1972.000000 1973.000000 1974.000000 1975.000000 1976.000000 1977.000000 1978.000000 1979.000000 1980.000000 1981.000000 1982.000000 1983.000000 1984.000000 1985.000000 1986.000000 1987.000000 1988.000000 1989.000000 1990.000000 1991.000000 1992.000000 1993.000000 1994.000000 1995.000000 1996.000000 1997.000000 1998.000000 1999.000000 2000.000000 2001.000000 2002.000000 2003.000000 2004.000000 2005.000000 2006.000000 2007.000000 2008.000000 2009.000000 2010.000000 2011.000000 2012.000000 2013.000000 2014.000000 2015.000000 2016.000000 2017.000000 2018.000000 2019.000000 2020.000000 2021.000000 2022.000000 2023.000000 2024.000000 2025.000000 2026.000000 2027.000000 2028.000000 2029.000000 2030.000000 2031.000000 2032.000000 2033.000000 2034.000000 2035.000000 2036.000000 2037.000000 2038.000000 2039.000000 2040.000000 2041.000000 2042.000000 2043.000000 2044.000000 2045.000000 2046.000000 2047.000000 2048.000000 2049.000000 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Search"
      ],
      "metadata": {
        "id": "QAKJJDbmIQ25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name search.cu \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define DIV_ROUNDUP(NUM,DEN) ((NUM +(DEN-1))/DEN)\n",
        "\n",
        "#define CHECK(call)                                                            \\\n",
        "{                                                                              \\\n",
        "    const cudaError_t error = call;                                            \\\n",
        "    if (error != cudaSuccess)                                                  \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
        "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
        "                cudaGetErrorString(error));                                    \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "inline double seconds() {\n",
        "    struct timeval tp;\n",
        "    struct timezone tzp;\n",
        "    int i = gettimeofday(&tp, &tzp);\n",
        "    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n",
        "}\n",
        "\n",
        "\n",
        "int closest_multiple_of(int numToRound, int multiple){\n",
        "  assert(numToRound >0);\n",
        "\n",
        "  if (multiple == 0)\n",
        "    return numToRound;\n",
        "\n",
        "  int remainder = numToRound % multiple;\n",
        "  if (remainder == 0)\n",
        "    return numToRound;\n",
        "\n",
        "  return numToRound + multiple - remainder;\n",
        "}\n",
        "\n",
        "int next_power_of_two(int n){\n",
        "    int res=1;\n",
        "    while(res<n) {res <<= 1;}\n",
        "    return res;\n",
        "}\n",
        "\n",
        "__global__ void select_node(float *fitness, int *selected_node, const float random_num, const int bound){\n",
        "  extern __shared__ float sm[];\n",
        "  const int gtid = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "  const int tid = threadIdx.x;\n",
        "\n",
        "  if (gtid >= bound)\n",
        "    return;\n",
        "\n",
        "  /* compiler will do its magic to avoid branching */\n",
        "  if(tid==0)\n",
        "    if(gtid==0)\n",
        "      sm[tid] = 0.0f;\n",
        "    else\n",
        "      sm[tid] = fitness[gtid-1];\n",
        "  \n",
        "  sm[tid+1] = fitness[gtid];\n",
        "  __syncthreads();\n",
        "\n",
        "  if(random_num >= sm[tid] && random_num < sm[tid+1])\n",
        "    selected_node[0] = gtid;\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  int N = 1<<20;\n",
        "  int blockSize = 1024;\n",
        "  \n",
        "  int numBlocks = N/blockSize;\n",
        "  if(N%blockSize != 0)\n",
        "      numBlocks++;\n",
        "\n",
        "  printf(\"ARRAY OF SIZE %d BLOCKSIZE %d\\n\", N, blockSize);\n",
        "  printf(\"USING %d BLOCKS OF %d THREADS\\n\", numBlocks, blockSize);\n",
        "\n",
        "  //printf(\"\\nFitness array: \");\n",
        "  float h_v[N];\n",
        "  for(int i=0; i<N;i++) {\n",
        "    h_v[i] = (float) i;\n",
        "    //printf(\"%f \", h_v[i]);\n",
        "  }\n",
        "  //printf(\"\\n\");\n",
        "\n",
        "\n",
        "\tfloat *d_v;\n",
        "  int *d_output;\n",
        "\tCHECK(cudaMalloc((void **)&d_v, sizeof(float)*N));\n",
        "  CHECK(cudaMalloc((void **)&d_output, sizeof(int)));\n",
        "\n",
        "  CHECK(cudaMemcpy(d_v, h_v, sizeof(float)*N, cudaMemcpyHostToDevice));\n",
        "\n",
        "\n",
        "  float r = 14.9f;\n",
        "  printf(\"random number is %f\\n\", r);\n",
        "  select_node<<<numBlocks, blockSize, sizeof(float)*blockSize+1>>>(d_v, d_output, r, N);\n",
        "  \n",
        "  int selected_node;\n",
        "\tCHECK(cudaMemcpy(&selected_node, d_output, sizeof(int), cudaMemcpyDeviceToHost));\n",
        "  printf(\"selected node %d \\n\", selected_node);\n",
        "\n",
        "  CHECK(cudaFree(d_v));\n",
        "  CHECK(cudaFree(d_output));\n",
        "\n",
        "  CHECK(cudaDeviceSynchronize());\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sWhpfYYJIYt3",
        "outputId": "d86434d9-e25d-45cf-8260-60afaa0ee362"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/search.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -g -G src/search.cu -o search\n",
        "!./search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x6mlzSiIiWc",
        "outputId": "593658be-c4eb-4f24-ca77-6caef5955e3b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARRAY OF SIZE 1048576 BLOCKSIZE 1024\n",
            "USING 1024 BLOCKS OF 1024 THREADS\n",
            "random number is 14.900000\n",
            "selected node 15 \n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpu_aco_tsp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOG2Bokky5PxMzVSSIzApW6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoniobelotti/gpu_aco_tsp/blob/master/gpu_aco_tsp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcrTWUB87XmP",
        "outputId": "2765b5c0-c795-4899-87ef-d63748eb10ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 30 15:43:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAXh_1Eq7rG8",
        "outputId": "4fa0ef38-8e4c-433d-bbfa-0a350fdda850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "cOwUP61S90V5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![immagine.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "APLOYaQBSoqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comment this to enable output\n",
        "%%capture \n",
        "\n",
        "# remove default colab stuff\n",
        "!rm -rf sample_data \n",
        "\n",
        "#create directory structure\n",
        "!mkdir -p src/lib/cuda\n",
        "!mkdir -p src/lib/sequential\n",
        "\n",
        "# download TSPLIB intsances\n",
        "!git clone https://github.com/mastqe/tsplib.git data\n",
        "\n",
        "# Install nvcc colab plugin\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter\n",
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "id": "U26pok5QVVlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code"
      ],
      "metadata": {
        "id": "nO2j5EZ6XKSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sequential implementation"
      ],
      "metadata": {
        "id": "hfztUXOAXpew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Code to read TSPLIB instances\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yr4keply-C2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name lib/sequential/tsplib.h\n",
        "#ifndef TSPLIB_H\n",
        "#define TSPLIB_H\n",
        "\n",
        "#define ASCII_SLASH 47\n",
        "#define ASCII_0 48\n",
        "#define ASCII_9 57\n",
        "\n",
        "typedef struct node_t{\n",
        "    int id;\n",
        "    int x;\n",
        "    int y;\n",
        "} Node;\n",
        "\n",
        "typedef struct TSPInstance_t {\n",
        "    const int numOfNodes;\n",
        "    Node *nodes;\n",
        "    float *edgeCosts;\n",
        "} TSPInstance;\n",
        "\n",
        "\n",
        "TSPInstance tsp_instance_read(const char *filename);\n",
        "void tsp_instance_free(TSPInstance *instance);\n",
        "\n",
        "#endif //TSPLIB_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OjwZWOg0-MrC",
        "outputId": "82dc7b02-e19e-4d2d-a3c2-ea66df3850a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/sequential/tsplib.h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name lib/sequential/tsplib.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include \"tsplib.h\"\n",
        "\n",
        "\n",
        "TSPInstance tsp_instance_read(const char *filename) {\n",
        "    printf(\"Reading tsplib instances from %s\\n\", filename);\n",
        "\n",
        "    FILE *f = fopen(filename, \"r\");\n",
        "    if (f == NULL) {\n",
        "        printf(\"Error reading file!\");\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "    unsigned long filename_len = strlen(filename);\n",
        "    const char *s = filename + filename_len; // pointer to last char\n",
        "    for (; *s != ASCII_SLASH; s--); // scan backwards until / is found\n",
        "    for (; *s < ASCII_0 || *s > ASCII_9; s++); // scan forward until a digit is found\n",
        "\n",
        "    int num_of_nodes = strtol(s, NULL, 10);\n",
        "\n",
        "    char line_buff[64];\n",
        "    Node *nodes = malloc(sizeof *nodes * num_of_nodes);\n",
        "\n",
        "    while (fgets(line_buff, sizeof line_buff, f) != NULL &&\n",
        "           strncmp(line_buff, \"NODE_COORD_SECTION\", strlen(\"NODE_COORD_SECTION\")) != 0);\n",
        "\n",
        "    while (fgets(line_buff, sizeof line_buff, f) != NULL && strncmp(line_buff, \"EOF\", 3) != 0) {\n",
        "\n",
        "        int progr, x, y;\n",
        "\n",
        "        char *buff_cursor;\n",
        "        progr = strtol(line_buff, &buff_cursor, 10);\n",
        "        x = strtol(buff_cursor, &buff_cursor, 10);\n",
        "        y = strtol(buff_cursor, &buff_cursor, 10);\n",
        "\n",
        "        // convert to 0-indexed\n",
        "        progr -= 1;\n",
        "\n",
        "        nodes[progr].id = progr;\n",
        "        nodes[progr].x = x;\n",
        "        nodes[progr].y = y;\n",
        "\n",
        "    }\n",
        "\n",
        "    fclose(f);\n",
        "\n",
        "    TSPInstance instance = {.numOfNodes = num_of_nodes, .nodes = nodes};\n",
        "\n",
        "    float *edge_cost = malloc(sizeof(int) * num_of_nodes * num_of_nodes);\n",
        "\n",
        "    float deltaX, deltaY;\n",
        "    Node n1, n2;\n",
        "    float weight;\n",
        "    for (int i = 0; i < num_of_nodes; i++) {\n",
        "        for (int j = i; j < num_of_nodes; j++) {\n",
        "            n1 = nodes[i];\n",
        "            n2 = nodes[j];\n",
        "\n",
        "            deltaX = (float) (n1.x - n2.x);\n",
        "            deltaY = (float) (n1.y - n2.y);\n",
        "\n",
        "            weight = floorf(sqrtf(powf(deltaX, 2) + powf(deltaY,2)));\n",
        "\n",
        "            edge_cost[n1.id * num_of_nodes + n2.id] = weight;\n",
        "            edge_cost[n2.id * num_of_nodes + n1.id] = weight;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    instance.edgeCosts = edge_cost;\n",
        "    return instance;\n",
        "}\n",
        "\n",
        "void tsp_instance_free(TSPInstance *instance) {\n",
        "    free(instance->nodes);\n",
        "    free(instance->edgeCosts);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MJh4zi2eAQec",
        "outputId": "da0a5025-c1dc-43da-e866-5ef2dd0f9b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/sequential/tsplib.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv src/lib/sequential/tsplib.cu src/lib/sequential/tsplib.c"
      ],
      "metadata": {
        "id": "x3k0OZg0KHCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Algorithm"
      ],
      "metadata": {
        "id": "jl0p9CZ4BAVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name lib/sequential/aco_tsp_sequential.h\n",
        "#ifndef ACO_TSP_SEQUENTIAL_H\n",
        "#define ACO_TSP_SEQUENTIAL_H\n",
        "\n",
        "#include \"tsplib.h\"\n",
        "\n",
        "void aco_tsp_sequential(\n",
        "    TSPInstance instance,\n",
        "    const float ALPHA,\n",
        "    const float BETA, \n",
        "    const float RHO, \n",
        "    const float Q, \n",
        "    const float PHEROMONE_LB, \n",
        "    const int MAX_ITERATIONS,\n",
        "    const int STAGNATION_THRESHOLD\n",
        ");\n",
        "\n",
        "#endif // ACO_TSP_SEQUENTIAL_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JrsnhpLyaLMS",
        "outputId": "55f76179-0d1c-40a1-ad15-720f071d6c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/sequential/aco_tsp_sequential.h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cuda plugin requires .cu extension... change it later to .c\n",
        "# using %%cuda instead of %%writefile becaus writefile disables syntax highlighting\n",
        "\n",
        "%%cuda --name lib/sequential/aco_tsp_sequential.cu\n",
        "#include <stdio.h>\n",
        "#include <limits.h>\n",
        "#include <stdbool.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "\n",
        "#include \"aco_tsp_sequential.h\"\n",
        "\n",
        "float randf(float right) {\n",
        "    return ((float) rand() / (float) RAND_MAX) * right;\n",
        "}\n",
        "\n",
        "float pheromone_initialization(float *pheromones, const float *edge_cost, int N) {\n",
        "    /* BUILD greedy path */\n",
        "    int path[N];\n",
        "    float path_cost = 0;\n",
        "    bool visited[N];\n",
        "\n",
        "    int id_first_node = (int) random() % N;\n",
        "    visited[id_first_node] = true;\n",
        "\n",
        "    int current_node = id_first_node;\n",
        "    for (int i = 1; i < N; i++) {\n",
        "        int closest_node = -1;\n",
        "        float closest_node_cost = (float) INT_MAX;\n",
        "\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            if (!visited[j] && current_node != j && edge_cost[current_node * N + j] < closest_node_cost) {\n",
        "                closest_node_cost = edge_cost[current_node * N + j];\n",
        "                closest_node = j;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        path[current_node] = closest_node;\n",
        "        visited[closest_node] = true;\n",
        "        current_node = closest_node;\n",
        "        path_cost += closest_node_cost;\n",
        "    }\n",
        "\n",
        "    /* set pheromone to N/greedy path cost */\n",
        "    for (int i = 0; i < N * N; ++i)\n",
        "        pheromones[i] = (float) N / (float) path_cost;\n",
        "\n",
        "    \n",
        "}\n",
        "\n",
        "void build_paths(int *ant_paths_mx, float *pheromone_trails, float *edge_costs, int N, const float ALPHA, const float BETA) {\n",
        "    for (int i = 0; i < N * N; i++) ant_paths_mx[i] = -1;\n",
        "\n",
        "    bool *unvisited_nodes_mx = malloc(sizeof *unvisited_nodes_mx * N * N);\n",
        "    for (int i = 0; i < N * N; i++) unvisited_nodes_mx[i] = true;\n",
        "\n",
        "    float *edge_fitness_mx = malloc(sizeof *edge_fitness_mx *N * N);\n",
        "    for (int r = 0; r < N; ++r)\n",
        "        for (int c = 0; c < N; ++c)\n",
        "            edge_fitness_mx[r * N + c] =\n",
        "                    r == c ? 0 : powf(pheromone_trails[r * N + c], ALPHA) / powf(edge_costs[r * N + c], BETA);\n",
        "\n",
        "    // build every ant's path\n",
        "    for (int ant_id = 0; ant_id < N; ++ant_id) {\n",
        "\n",
        "        // select random starting node\n",
        "        int id_first_node = (int) random() % N;\n",
        "        unvisited_nodes_mx[ant_id * N + id_first_node] = false;\n",
        "\n",
        "        int current_node_id = id_first_node;\n",
        "        for (int visited_nodes = 1; visited_nodes < N; visited_nodes++) {\n",
        "            float prefix_sum[N];\n",
        "            for (int j = 0; j < N; j++) {\n",
        "                bool mask = unvisited_nodes_mx[ant_id * N + j];\n",
        "                float fitness = edge_fitness_mx[current_node_id * N + j];\n",
        "                prefix_sum[j] = (j > 0 ? prefix_sum[j - 1] : 0.0f) + ((float) mask * fitness);\n",
        "            }\n",
        "\n",
        "            float random_number = randf(prefix_sum[N - 1]);\n",
        "            for (int j = 0; j < N; ++j) {\n",
        "                float ps_prev = j > 0 ? prefix_sum[j - 1] : 0.0f;\n",
        "                if (random_number >= ps_prev && random_number < prefix_sum[j]) {\n",
        "                    ant_paths_mx[ant_id * N + current_node_id] = j;\n",
        "                    unvisited_nodes_mx[ant_id * N + j] = false;\n",
        "                    current_node_id = j;\n",
        "                    break;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        ant_paths_mx[ant_id * N + current_node_id] = id_first_node;\n",
        "    }\n",
        "\n",
        "    free(edge_fitness_mx);\n",
        "    free(unvisited_nodes_mx);\n",
        "}\n",
        "\n",
        "int update_paths_len(const int *ant_paths_mx, float *ant_paths_len, const float *edge_cost, int N) {\n",
        "    // keep track of the ant id with the shortest path\n",
        "    int best_path_ant_id = -1;\n",
        "    float best_path = (float) INT_MAX;\n",
        "\n",
        "    for (int ant_id = 0; ant_id < N; ++ant_id) {\n",
        "        // calculate cost of ant(ant_id) path\n",
        "        ant_paths_len[ant_id] = 0;\n",
        "        int current_node = 0;\n",
        "        int next_node = ant_paths_mx[ant_id * N + current_node];\n",
        "\n",
        "        for (int i = 0; i < N; ++i) {\n",
        "            ant_paths_len[ant_id] += edge_cost[current_node * N + next_node];\n",
        "            current_node = next_node;\n",
        "            next_node = ant_paths_mx[ant_id * N + current_node];\n",
        "        }\n",
        "\n",
        "        if (ant_paths_len[ant_id] < best_path) {\n",
        "            best_path = ant_paths_len[ant_id];\n",
        "            best_path_ant_id = ant_id;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return best_path_ant_id;\n",
        "}\n",
        "\n",
        "void pheromone_evaporation(float *pheromones, int N, const float RHO, const float PHEROMONE_LB) {\n",
        "    for (int i = 0; i < N * N; ++i)\n",
        "        pheromones[i] = fmaxf((1 - RHO) * pheromones[i], PHEROMONE_LB);\n",
        "}\n",
        "\n",
        "void pheromone_update(float *pheromones, const int *paths, const float *paths_len, int N, const float Q, const float PHEROMONE_LB) {\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = i; j < N; ++j) {\n",
        "            float previous_pheromone_value = pheromones[i * N + j];\n",
        "            float addition = 0.0f;\n",
        "            for (int ant_id = 0; ant_id < N; ++ant_id)\n",
        "                // if edge (i,j) is in path of ant ant_id\n",
        "                if (paths[ant_id * N + i] == j)\n",
        "                    addition += Q / (float) paths_len[ant_id];\n",
        "\n",
        "\n",
        "            pheromones[i * N + j] = fmaxf(previous_pheromone_value + addition, PHEROMONE_LB);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void aco_tsp_sequential(\n",
        "    TSPInstance instance,\n",
        "    const float ALPHA,\n",
        "    const float BETA, \n",
        "    const float RHO, \n",
        "    const float Q, \n",
        "    const float PHEROMONE_LB, \n",
        "    const int MAX_ITERATIONS,\n",
        "    const int STAGNATION_THRESHOLD\n",
        ")\n",
        "{\n",
        "    int N = instance.numOfNodes;\n",
        "    float *pheromone_mx = malloc(sizeof *pheromone_mx * N * N);\n",
        "    int   *paths_mx = malloc(sizeof *paths_mx *N * N);\n",
        "    float paths_len[N];\n",
        "    int best_path[N];\n",
        "    float best_path_len = (float) INT_MAX;\n",
        "\n",
        "    pheromone_initialization(pheromone_mx, instance.edgeCosts, N);\n",
        "    int stagnation_counter = 0;\n",
        "    for (int iter = 0; iter < MAX_ITERATIONS && stagnation_counter < STAGNATION_THRESHOLD; ++iter, ++stagnation_counter) {\n",
        "        printf(\"Generation %d of %d\", iter + 1, MAX_ITERATIONS);\n",
        "        fflush(stdout);\n",
        "      \n",
        "        build_paths(paths_mx, pheromone_mx, instance.edgeCosts, N, ALPHA, BETA);\n",
        "        int current_iteration_best_ant = update_paths_len(paths_mx, paths_len, instance.edgeCosts, N);\n",
        "\n",
        "        pheromone_evaporation(pheromone_mx, N, RHO, PHEROMONE_LB);\n",
        "        pheromone_update(pheromone_mx, paths_mx, paths_len, N, Q, PHEROMONE_LB);\n",
        "\n",
        "        if (paths_len[current_iteration_best_ant] < best_path_len) {\n",
        "            best_path_len = paths_len[current_iteration_best_ant];\n",
        "\n",
        "            // save best path\n",
        "            for (int l = 0; l < instance.numOfNodes; ++l)\n",
        "                best_path[l] = paths_mx[current_iteration_best_ant * N + l];\n",
        "\n",
        "            // there's an improvement reset stagnation counter\n",
        "            stagnation_counter = 0;\n",
        "        }\n",
        "\n",
        "        printf(\"\\r\");\n",
        "        fflush(stdout);\n",
        "    }\n",
        "    \n",
        "    free(pheromone_mx);\n",
        "    free(paths_mx);\n",
        "    \n",
        "    char *prefix = stagnation_counter == STAGNATION_THRESHOLD ? \"Stopped for stagnation!\\n\" : \"\";\n",
        "    printf(\"%sBest Path has len: %f\\n\", prefix, best_path_len);\n",
        "    for (int j = 0; j < instance.numOfNodes; ++j) printf(\"%d,\", best_path[j] + 1);\n",
        "    printf(\"\\n\");\n",
        "    fflush(stdout);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wEDt2dWFAWvq",
        "outputId": "5a4bec06-23a7-4f0d-88d8-46fa801da0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/sequential/aco_tsp_sequential.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/src/lib/sequential/aco_tsp_sequential.cu /content/src/lib/sequential/aco_tsp_sequential.c"
      ],
      "metadata": {
        "id": "-myfmsTlWmST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GPU implementation"
      ],
      "metadata": {
        "id": "ns594U-lTx8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name lib/cuda/common.h\n",
        "#include <sys/time.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#ifndef _COMMON_H\n",
        "#define _COMMON_H\n",
        "\n",
        "#define CHECK(call)                                                            \\\n",
        "{                                                                              \\\n",
        "    const cudaError_t error = call;                                            \\\n",
        "    if (error != cudaSuccess)                                                  \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
        "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
        "                cudaGetErrorString(error));                                    \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CURAND(call)                                                     \\\n",
        "{                                                                              \\\n",
        "    curandStatus_t err;                                                        \\\n",
        "    if ((err = (call)) != CURAND_STATUS_SUCCESS)                               \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CURAND error %d at %s:%d\\n\", err, __FILE__,       \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#endif // _COMMON_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WCmYLZwKhss1",
        "outputId": "3d30ef06-d6c9-4040-afa8-dc43940c66a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/cuda/common.h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm"
      ],
      "metadata": {
        "id": "CXmGFi4EXg6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name lib/cuda/aco_tsp_cuda.h\n",
        "#ifndef ACO_TSP_CUDA_H\n",
        "#define ACO_TSP_CUDA_H\n",
        "\n",
        "#include \"../sequential/tsplib.h\"\n",
        "#include \"./common.h\"\n",
        "\n",
        "#define DIV_ROUNDUP(NUM,DEN) ((NUM +(DEN-1))/DEN)\n",
        "\n",
        "void aco_tsp_cuda(\n",
        "    TSPInstance instance, \n",
        "    const float ALPHA,\n",
        "    const float BETA, \n",
        "    const float RHO, \n",
        "    const float Q, \n",
        "    const float PHEROMONE_LB, \n",
        "    const int MAX_ITERATIONS,\n",
        "    const int STAGNATION_THRESHOLD\n",
        ");\n",
        "\n",
        "#endif // ACO_TSP_CUDA_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "66GSPIswefn_",
        "outputId": "99e10a4a-9317-407d-991e-1f7309a8523d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/cuda/aco_tsp_cuda.h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name lib/cuda/aco_tsp_cuda.cu\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <assert.h>\n",
        "\n",
        "#include \"aco_tsp_cuda.h\"\n",
        "\n",
        "__global__ void pheromone_reset(float *pheromone_mx, const int N, const float PHEROMONE_LB){\n",
        "    const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < N*N)\n",
        "      pheromone_mx[idx] = PHEROMONE_LB;\n",
        "}\n",
        "\n",
        "__global__ void custom_blelloch_prefix_sum(float *data, bool *mask, int n) {\n",
        "  /*\n",
        "  Blelloch's prefix scan implementation modified to be inclusive instead of exclusive.\n",
        "  Each block requires n+1 floats of shared memory\n",
        "\n",
        "  from gpu gems 3\n",
        "  */\n",
        "\n",
        "  extern __shared__ float temp[];\n",
        "  \n",
        "  int thid = threadIdx.x;\n",
        "  int gtid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int offset = 1;\n",
        "    \n",
        "  // load input into shared memory \n",
        "  temp[2*thid] = data[2*gtid] * mask[2*gtid]; \n",
        "  temp[2*thid+1] = data[2*gtid+1] * mask[2*gtid+1];\n",
        "\n",
        "  // build sum in place up the tree\n",
        "  for (int d = n>>1; d > 0; d >>= 1) {\n",
        "    __syncthreads();\n",
        "\n",
        "    if (thid < d) { \n",
        "      int ai = offset*(2*thid+1)-1;     \n",
        "      int bi = offset*(2*thid+2)-1;  \n",
        "      temp[bi] += temp[ai];    \n",
        "    }\n",
        "    offset *= 2; \n",
        "  }\n",
        "\n",
        "  if (thid == 0) { \n",
        "      temp[n] = temp[n-1]; \n",
        "      temp[n-1] = 0.0f;\n",
        "  }\n",
        "\n",
        "  // traverse down tree & build scan \n",
        "  for (int d = 1; d < n; d *= 2) {      \n",
        "    offset >>= 1;\n",
        "    __syncthreads();\n",
        "    if (thid < d) {\n",
        "      int ai = offset*(2*thid+1)-1;\n",
        "      int bi = offset*(2*thid+2)-1;\n",
        "      float t = temp[ai]; temp[ai] = temp[bi]; temp[bi] += t;\n",
        "    }\n",
        "  }\n",
        "  \n",
        "  __syncthreads();\n",
        "\n",
        "  data[2*gtid] = temp[2*thid+1];\n",
        "  data[2*gtid+1] = temp[2*thid+2];\n",
        "} \n",
        "\n",
        "        \n",
        "__global__ void population_reset(int *paths_mx, int N){\n",
        "    const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < N*N)\n",
        "      paths_mx[idx] = -1;\n",
        "}\n",
        "\n",
        "__global__ void unvisited_node_reset(bool *unvisited_node_mx, int N){\n",
        "    const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < N*N)\n",
        "      unvisited_node_mx[idx] = true;\n",
        "}\n",
        "\n",
        "__global__ void build_paths(int *paths_mx, float *pheromone_mx, float *edge_costs, bool *unvisited_nodes_mx, int N, float ALPHA, float BETA){}\n",
        "\n",
        "\n",
        "__global__ void edge_fitness_update(float *edge_fitness_mx, float *pheromone_mx, float *edge_costs_mx, const int N, const float ALPHA, const float BETA){\n",
        "    const int row_idx = blockIdx.x;\n",
        "    const int col_idx = threadIdx.x;\n",
        "    const int idx = row_idx * blockDim.x + col_idx;\n",
        "\n",
        "    // TODO: branching trick possible??\n",
        "    //if (row_idx == col_idx){\n",
        "    //    edge_fitness_mx[idx] = 0;\n",
        "    //}else if (idx < N*N){\n",
        "    //    edge_fitness_mx[idx] = powf(pheromone_mx[idx], ALPHA) / powf(edge_costs_mx[idx], BETA);\n",
        "    //}\n",
        "    if (idx < N*N && row_idx != col_idx)\n",
        "      edge_fitness_mx[idx] = powf(pheromone_mx[idx], ALPHA) / powf(edge_costs_mx[idx], BETA);\n",
        "}\n",
        "\n",
        "int closest_multiple_of(int numToRound, int multiple){\n",
        "  assert(numToRound >0);\n",
        "\n",
        "  if (multiple == 0)\n",
        "    return numToRound;\n",
        "\n",
        "  int remainder = numToRound % multiple;\n",
        "  if (remainder == 0)\n",
        "    return numToRound;\n",
        "\n",
        "  return numToRound + multiple - remainder;\n",
        "}\n",
        "\n",
        "void aco_tsp_cuda(\n",
        "    TSPInstance instance,\n",
        "    const float ALPHA,\n",
        "    const float BETA, \n",
        "    const float RHO, \n",
        "    const float Q, \n",
        "    const float PHEROMONE_LB, \n",
        "    const int MAX_ITERATIONS,\n",
        "    const int STAGNATION_THRESHOLD\n",
        ") \n",
        "{\n",
        "    /* HOST */\n",
        "    const int N = instance.numOfNodes;\n",
        "\n",
        "    const int BLOCKSIZE = 256; \n",
        "\n",
        "    /* number used to pad array to nearest BLOCKSIZE multiple. This is needed\n",
        "        for some operations like prefix sum. */\n",
        "    int block_multiple_N = closest_multiple_of(N, BLOCKSIZE);\n",
        " \n",
        "    /*\n",
        "    float paths_len[N];\n",
        "    int best_path[N];\n",
        "    float best_path_len = (float) INT_MAX;\n",
        "    */\n",
        "\n",
        "    /* DEVICE */\n",
        "    float *pheromone_mx;\n",
        "    int *paths_mx;\n",
        "    bool *unvisited_nodes_mx;\n",
        "    float *edge_costs_mx;\n",
        "    float *edge_fitness_mx;\n",
        "\n",
        "    CHECK(cudaMalloc((void **)&pheromone_mx, sizeof(float)*N*N));\n",
        "    CHECK(cudaMalloc((void **)&paths_mx, sizeof(int)*N*N));\n",
        "    CHECK(cudaMalloc((void **)&edge_costs_mx, sizeof(float)*N*N));\n",
        "    CHECK(cudaMalloc((void **)&edge_fitness_mx, sizeof(float)*N*N));\n",
        "    CHECK(cudaMalloc((void **)&unvisited_nodes_mx, sizeof(bool)*N*N));\n",
        " \n",
        "    CHECK(cudaMemcpy(edge_costs_mx, instance.edgeCosts, sizeof(float)*N*N, cudaMemcpyHostToDevice));\n",
        "    \n",
        "    pheromone_reset<<<DIV_ROUNDUP(N,BLOCKSIZE),BLOCKSIZE>>>(pheromone_mx, N, PHEROMONE_LB);\n",
        " \n",
        "    cudaStream_t streams[3];\n",
        "    cudaStreamCreate(&streams[0]);\n",
        "    cudaStreamCreate(&streams[1]);\n",
        "    cudaStreamCreate(&streams[2]);\n",
        "    \n",
        "    cudaEvent_t events[3];\n",
        "    cudaEventCreate(&events[0]);\n",
        "    cudaEventCreate(&events[1]);\n",
        "    cudaEventCreate(&events[2]);\n",
        "\n",
        "    int stagnation_counter = 0;\n",
        "    for (int iter = 0; iter < MAX_ITERATIONS && stagnation_counter < STAGNATION_THRESHOLD; ++iter, ++stagnation_counter) {\n",
        "        printf(\"Generation %d of %d\", iter + 1, MAX_ITERATIONS);\n",
        "        fflush(stdout);\n",
        "\n",
        "        \n",
        "        population_reset<<<DIV_ROUNDUP(N,BLOCKSIZE),BLOCKSIZE,0,streams[0]>>>(paths_mx, N);\n",
        "        cudaEventRecord(events[0], streams[0]);\n",
        "        unvisited_node_reset<<<DIV_ROUNDUP(N,BLOCKSIZE),BLOCKSIZE,0,streams[1]>>>(unvisited_nodes_mx, N);\n",
        "        cudaEventRecord(events[1], streams[1]);\n",
        "        edge_fitness_update<<<DIV_ROUNDUP(N,BLOCKSIZE),BLOCKSIZE,0,streams[2]>>>(edge_fitness_mx, pheromone_mx, edge_costs_mx, N, ALPHA, BETA);\n",
        "        cudaEventRecord(events[2], streams[2]);\n",
        "\n",
        "        // for i=0 to N i.e. each node of the path\n",
        "        //prefix_sum<<<N, N, N*sizeof(int)>>>(edge_fitness_mx, unvisited_nodes);\n",
        "        \n",
        "        cudaEventSynchronize(events[0]);\n",
        "        cudaEventSynchronize(events[1]);\n",
        "        cudaEventSynchronize(events[2]);\n",
        "\n",
        "\n",
        "        break;\n",
        "\n",
        "        //build_paths<<<>>>(paths_mx, pheromone_mx, instance.edgeCosts, unvisited_nodes_mx, N, ALPHA, BETA);\n",
        "    }    \n",
        "\n",
        "    /*\n",
        "    printf(\"%sBest Path has len: %f\\n\", stagnation_counter == STAGNATION_THRESHOLD ? \"Stopped for stagnation!\" :\"\", best_path_len);\n",
        "    for (int j = 0; j < instance.numOfNodes; ++j) printf(\"%d,\", best_path[j] + 1);\n",
        "    printf(\"\\n\");\n",
        "    fflush(stdout);\n",
        "    */\n",
        "\n",
        "\n",
        "    cudaStreamDestroy(streams[0]);\n",
        "    cudaStreamDestroy(streams[1]);\n",
        "    cudaStreamDestroy(streams[2]);\n",
        "\n",
        "    cudaEventDestroy(events[0]);\n",
        "    cudaEventDestroy(events[1]);\n",
        "    cudaEventDestroy(events[2]);\n",
        " \n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    \n",
        "    cudaFree(pheromone_mx);\n",
        "    cudaFree(paths_mx);\n",
        "    cudaFree(unvisited_nodes_mx);\n",
        "    cudaFree(edge_costs_mx);\n",
        "    cudaFree(edge_fitness_mx);\n",
        "     \n",
        "    CHECK(cudaDeviceReset());\n",
        "}"
      ],
      "metadata": {
        "id": "0xAWDFX-79iX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7efc8acc-22e8-4010-949b-8ca56cf2159e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lib/cuda/aco_tsp_cuda.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Glue"
      ],
      "metadata": {
        "id": "1eO7fmrhZDqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/CMakeLists.txt\n",
        "cmake_minimum_required(VERSION 3.21)\n",
        "project(ACO_TSP LANGUAGES CUDA C)\n",
        "\n",
        "#######################\n",
        "###   SEQUENTIAL\n",
        "add_library(\n",
        "  aco_tsp_sequential STATIC \n",
        "  \n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/sequential/tsplib.h\n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/sequential/tsplib.c \n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/sequential/aco_tsp_sequential.h \n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/sequential/aco_tsp_sequential.c \n",
        ")\n",
        "\n",
        "target_include_directories(aco_tsp_sequential PUBLIC ${CMAKE_CURRENT_SOURCE_DIR})\n",
        "\n",
        "#######################\n",
        "###   CUDA\n",
        "\n",
        "set(CUDA_SEPARABLE_COMPILATION ON)\n",
        "\n",
        "add_library(\n",
        "  aco_tsp_cuda STATIC \n",
        "\n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/cuda/aco_tsp_cuda.h\n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/cuda/aco_tsp_cuda.cu \n",
        "  \n",
        "  ${CMAKE_CURRENT_SOURCE_DIR}/lib/cuda/common.h\n",
        ")\n",
        "target_include_directories (aco_tsp_cuda PUBLIC ${CMAKE_CURRENT_SOURCE_DIR})\n",
        "set_target_properties(aco_tsp_cuda PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n",
        "\n",
        "\n",
        "########### MAIN ###########\n",
        "add_executable(ACO_TSP main.cu)\n",
        "\n",
        "target_compile_options(ACO_TSP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:\n",
        "                       --generate-line-info\n",
        "                       --use_fast_math\n",
        "                       --relocatable-device-code=true\n",
        "                       -arch=sm_37\n",
        "                       >)\n",
        "\n",
        "target_link_libraries(${PROJECT_NAME} PUBLIC m)\n",
        "target_link_libraries(${PROJECT_NAME} PUBLIC aco_tsp_cuda)\n",
        "target_link_libraries(${PROJECT_NAME} PUBLIC aco_tsp_sequential)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd2bR56ZRUyJ",
        "outputId": "8d6be2b0-1aee-4ad8-9310-52af89d1ce56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/CMakeLists.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name main.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "extern \"C\" { \n",
        "  #include \"./lib/sequential/tsplib.h\"\n",
        "  #include \"./lib/sequential/aco_tsp_sequential.h\"\n",
        "}\n",
        "#include \"./lib/cuda/aco_tsp_cuda.h\"\n",
        "\n",
        "\n",
        "#define RUN_CPU false\n",
        "#define RUN_GPU true\n",
        "\n",
        "#define BASE_DATA_FOLDER \"/content/data/\"\n",
        "\n",
        "/*\n",
        "ALPHA importance of pheromone trail\n",
        "BETA  importance of heuristic visibility\n",
        "RHO   pheromone evaporation rate\n",
        "Q     numerator of pheromone update\n",
        "*/\n",
        "static const float ALPHA = 1.0f;\n",
        "static const float BETA = 3.0f;\n",
        "static const float RHO = 0.8f;\n",
        "static const float Q = 1.0f;\n",
        "static const float PHEROMONE_LB = 0.01f;\n",
        "static const int MAX_ITERATIONS = 100000;\n",
        "static const int STAGNATION_THRESHOLD = MAX_ITERATIONS/5;\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    if (argc<2){\n",
        "      printf(\"Specify filname\\n\");\n",
        "      return -1;\n",
        "    }\n",
        "\n",
        "    char filenameBuffer[128];\n",
        "    strcpy(filenameBuffer, BASE_DATA_FOLDER);\n",
        "    strcat(filenameBuffer, argv[1]);\n",
        "    \n",
        "    TSPInstance instance = tsp_instance_read(filenameBuffer);\n",
        "\n",
        "  \n",
        "    if(RUN_CPU){\n",
        "      srand(time(NULL));\n",
        "      \n",
        "      clock_t starts = clock(), diffs;\n",
        "      \n",
        "      aco_tsp_sequential(instance, ALPHA, BETA, RHO, Q, PHEROMONE_LB, MAX_ITERATIONS, STAGNATION_THRESHOLD);\n",
        "      \n",
        "      diffs = clock() - starts;\n",
        "      int msecs = diffs * 1000 / CLOCKS_PER_SEC;\n",
        "      printf(\"\\nSequential took %d seconds %d milliseconds\\n\", msecs/1000, msecs%1000);\n",
        "    }\n",
        "\n",
        "\n",
        "    if(RUN_GPU){\n",
        "      cudaSetDevice(1);\n",
        "\n",
        "      clock_t startc = clock(), diffc;\n",
        "\n",
        "      aco_tsp_cuda(instance, ALPHA, BETA, RHO, Q, PHEROMONE_LB, 1, STAGNATION_THRESHOLD);\n",
        "\n",
        "      cudaDeviceSynchronize();\n",
        "      diffc = clock() - startc;\n",
        "      int msecc = diffc * 1000 / CLOCKS_PER_SEC;\n",
        "      printf(\"\\nCuda took %d seconds %d milliseconds\\n\", msecc/1000, msecc%1000);\n",
        "\n",
        "    }\n",
        "\n",
        "    tsp_instance_free(&instance);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ugQP-dqeLRTG",
        "outputId": "0a179feb-60a9-4c13-a5d6-5cc0469c0888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/main.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p cmake_build\n",
        "%cd cmake_build\n",
        "\n",
        "!cmake ../src\n",
        "!cmake --build .\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd9YRaN1e_LW",
        "outputId": "4e021830-42ae-4112-b9f0-7902053f334a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cmake_build\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/cmake_build\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target aco_tsp_sequential\u001b[0m\n",
            "[ 37%] Built target aco_tsp_sequential\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target aco_tsp_cuda\u001b[0m\n",
            "[ 62%] Built target aco_tsp_cuda\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target ACO_TSP\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CUDA object CMakeFiles/ACO_TSP.dir/main.cu.o\u001b[0m\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "[ 87%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/ACO_TSP.dir/cmake_device_link.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CUDA executable ACO_TSP\u001b[0m\n",
            "[100%] Built target ACO_TSP\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./cmake_build/ACO_TSP brd14051.tsp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6A8O6SeS8uq",
        "outputId": "ad395ff7-c613-420a-9d4c-4778068e6584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading tsplib instances from /content/data/brd14051.tsp\n",
            "Generation 1 of 1\n",
            "Cuda took 0 seconds 637 milliseconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cgIup4KaL9Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DEV"
      ],
      "metadata": {
        "id": "kPToz950sd-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prefix Sum"
      ],
      "metadata": {
        "id": "m-MkUntOskIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name gems.cu \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define DIV_ROUNDUP(NUM,DEN) ((NUM +(DEN-1))/DEN)\n",
        "\n",
        "#define CHECK(call)                                                            \\\n",
        "{                                                                              \\\n",
        "    const cudaError_t error = call;                                            \\\n",
        "    if (error != cudaSuccess)                                                  \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
        "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
        "                cudaGetErrorString(error));                                    \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "inline double seconds() {\n",
        "    struct timeval tp;\n",
        "    struct timezone tzp;\n",
        "    int i = gettimeofday(&tp, &tzp);\n",
        "    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void prescan(float *g_odata, float *g_idata, int n) { \n",
        "  extern __shared__ float temp[];\n",
        "  \n",
        "  int thid = threadIdx.x;\n",
        "  int gtid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int offset = 1; \n",
        "    \n",
        "  // load input into shared memory\n",
        "  temp[2*thid] = g_idata[2*gtid]; \n",
        "  temp[2*thid+1] = g_idata[2*gtid+1];\n",
        "\n",
        "  // build sum in place up the tree\n",
        "  for (int d = n>>1; d > 0; d >>= 1) {\n",
        "    __syncthreads();\n",
        "\n",
        "    if (thid < d) { \n",
        "      int ai = offset*(2*thid+1)-1;     \n",
        "      int bi = offset*(2*thid+2)-1;\n",
        "      \n",
        "      temp[bi] += temp[ai];    \n",
        "    }\n",
        "    offset *= 2; \n",
        "  }\n",
        "\n",
        "  if (thid == 0) { temp[n - 1] = 0; } // clear the last element  \n",
        "\n",
        "  // traverse down tree & build scan \n",
        "  for (int d = 1; d < n; d *= 2) {      \n",
        "    offset >>= 1;\n",
        "    __syncthreads();\n",
        "    if (thid < d) {\n",
        "      int ai = offset*(2*thid+1)-1;\n",
        "      int bi = offset*(2*thid+2)-1;\n",
        "      float t = temp[ai]; temp[ai] = temp[bi]; temp[bi] += t;\n",
        "    }\n",
        "  }\n",
        "  \n",
        "  __syncthreads();\n",
        "\n",
        "  g_odata[2*gtid] = temp[2*thid];\n",
        "  g_odata[2*gtid+1] = temp[2*thid+1];\n",
        "} \n",
        "\n",
        "\n",
        "__global__ void custom_prescan(float *data, bool *mask, int n, float *intermediate_sum, const int bound) { \n",
        "  extern __shared__ float temp[];\n",
        "  \n",
        "  int thid = threadIdx.x;\n",
        "  int gtid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int offset = 1;\n",
        "    \n",
        "  // load input into shared memory\n",
        "  temp[2*thid] = data[2*gtid] * mask[2*gtid]; \n",
        "  temp[2*thid+1] = data[2*gtid+1] * mask[2*gtid+1];\n",
        "  \n",
        "  // build sum in place up the tree\n",
        "  for (int d = n>>1; d > 0; d >>= 1) {\n",
        "    __syncthreads();\n",
        "\n",
        "    if (thid < d) { \n",
        "      int ai = offset*(2*thid+1)-1;     \n",
        "      int bi = offset*(2*thid+2)-1;  \n",
        "      temp[bi] += temp[ai];    \n",
        "    }\n",
        "    offset *= 2; \n",
        "  }\n",
        "\n",
        "  if (thid == 0) { \n",
        "    temp[n] = temp[n-1]; \n",
        "    temp[n-1] = 0.0f;\n",
        "    intermediate_sum[blockIdx.x] = temp[n];\n",
        "  }\n",
        "\n",
        "  // traverse down tree & build scan \n",
        "  for (int d = 1; d < n; d *= 2) {      \n",
        "    offset >>= 1;\n",
        "    __syncthreads();\n",
        "    if (thid < d) {\n",
        "      int ai = offset*(2*thid+1)-1;\n",
        "      int bi = offset*(2*thid+2)-1;\n",
        "      float t = temp[ai]; temp[ai] = temp[bi]; temp[bi] += t;\n",
        "    }\n",
        "  }\n",
        "  \n",
        "  __syncthreads();\n",
        "\n",
        "  data[2*gtid] = temp[2*thid+1];\n",
        "  data[2*gtid+1] = temp[2*thid+2];\n",
        "} \n",
        "\n",
        "__global__ void apply_increment(float *cumsum, float *increment, const int n){\n",
        "  int gidx = blockIdx.x*blockDim.x +threadIdx.x;\n",
        "\n",
        "  if(gidx < n)\n",
        "    cumsum[gidx] += increment[blockIdx.x];\n",
        "}\n",
        "\n",
        "int closest_multiple_of(int numToRound, int multiple){\n",
        "  assert(numToRound >0);\n",
        "\n",
        "  if (multiple == 0)\n",
        "    return numToRound;\n",
        "\n",
        "  int remainder = numToRound % multiple;\n",
        "  if (remainder == 0)\n",
        "    return numToRound;\n",
        "\n",
        "  return numToRound + multiple - remainder;\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  int blockSize = 512;\n",
        "  int N = (2<<16) +0;\n",
        "\n",
        "  /* host side with the original size */\n",
        "  float h_v[N];\n",
        "  for(int i=0; i<N;i++) h_v[i] = 1;\n",
        "  bool h_mask[N];\n",
        "  for(int i=0; i<N;i++) h_mask[i] = true;\n",
        "  \n",
        "  int newN = closest_multiple_of(N, blockSize);\n",
        "\n",
        "  int numBlocks = newN/blockSize;\n",
        "  int threadsPerBlock = blockSize/2;\n",
        "\n",
        "\tfloat *d_v, *d_intermediary_sums;\n",
        "\tCHECK(cudaMalloc((void **)&d_v, sizeof(float)*newN));\n",
        "  CHECK(cudaMalloc((void **)&d_intermediary_sums, sizeof(float)*numBlocks));\n",
        "  bool *mask;\n",
        "  CHECK(cudaMalloc((void **)&mask, sizeof(bool)*newN));\n",
        "\n",
        "\n",
        "double iStart = seconds();\n",
        "\t\n",
        "  CHECK(cudaMemcpy(d_v, h_v, sizeof(float)*N, cudaMemcpyHostToDevice));\n",
        "  CHECK(cudaMemcpy(mask, h_mask, sizeof(bool)*N, cudaMemcpyHostToDevice));\n",
        "  \n",
        "  custom_prescan<<<numBlocks, threadsPerBlock, sizeof(float)*(blockSize+1)>>>(d_v, mask, blockSize, d_intermediary_sums, newN);\n",
        "  if(numBlocks>1){\n",
        "    prescan<<<1,numBlocks/2,sizeof(float)*numBlocks>>>(d_intermediary_sums,d_intermediary_sums, numBlocks);\n",
        "    apply_increment<<<numBlocks, threadsPerBlock*2>>>(d_v, d_intermediary_sums, newN);\n",
        "  }\n",
        "\n",
        "\tCHECK(cudaMemcpy(h_v, d_v, sizeof(float)*N, cudaMemcpyDeviceToHost));\n",
        "\n",
        "double iElaps = seconds() - iStart;\n",
        "printf(\"\\ncuda took: \\t %f sec\\n\", iElaps);\n",
        "\n",
        "  CHECK(cudaFree(d_v));\n",
        "\n",
        "  CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "  float test[N];\n",
        "  for(int i=0; i<N; i++) test[i] = 1;\n",
        "iStart = seconds();\n",
        "  for(int i=1; i<N; i++)\n",
        "    test[i] += test[i-1];\n",
        "\n",
        "iElaps = seconds() - iStart;\n",
        "printf(\"cpu took: \\t %f sec\\n\", iElaps);\n",
        "\n",
        "  for(int i=0; i<N; i++){\n",
        "    if(h_v[i] != test[i])\n",
        "      printf(\"i %d gpu %f, cpu %f\\n\", i, h_v[i], test[i]);\n",
        "  }\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uD6ygRElLqQM",
        "outputId": "2c25d50e-b6ed-4456-866d-248bbc2bba8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/gems.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc src/gems.cu -o example\n",
        "!ncu ./example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty1J2Q-VRzWH",
        "outputId": "f03e7216-25e0-4e34-f9d4-6e7cbf5c1a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 4255 (/content/example)\n",
            "==PROF== Profiling \"custom_prescan\" - 0: 0%....50%....100% - 8 passes\n",
            "==PROF== Profiling \"prescan(float *, float *, int)\" - 1: 0%....50%....100% - 8 passes\n",
            "==PROF== Profiling \"apply_increment\" - 2: 0%....50%....100% - 8 passes\n",
            "\n",
            "cuda took: \t 1.146219 sec\n",
            "cpu took: \t 0.000472 sec\n",
            "==PROF== Disconnected from process 4255\n",
            "[4255] example@127.0.0.1\n",
            "  custom_prescan(float *, bool *, int, float *, int), 2022-Aug-30 15:43:50, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.83\n",
            "    SM Frequency                                                             cycle/usecond                         565.55\n",
            "    Elapsed Cycles                                                                   cycle                         22,213\n",
            "    Memory [%]                                                                           %                          40.38\n",
            "    DRAM Throughput                                                                      %                           6.60\n",
            "    Duration                                                                       usecond                          39.26\n",
            "    L1/TEX Cache Throughput                                                              %                          80.76\n",
            "    L2 Cache Throughput                                                                  %                           4.29\n",
            "    SM Active Cycles                                                                 cycle                      19,006.55\n",
            "    Compute (SM) [%]                                                                     %                          39.66\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
            "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
            "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                        256\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                         256\n",
            "    Registers Per Thread                                                   register/thread                             17\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                            Kbyte/block                           2.05\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                         65,536\n",
            "    Waves Per SM                                                                                                     1.60\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                             10\n",
            "    Block Limit Shared Mem                                                           block                             14\n",
            "    Block Limit Warps                                                                block                              4\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          85.40\n",
            "    Achieved Active Warps Per SM                                                      warp                          27.33\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
            "          theoretical (100.0%) and measured achieved occupancy (85.4%) can be the result of warp scheduling overheads   \n",
            "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
            "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
            "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "  prescan(float *, float *, int), 2022-Aug-30 15:43:50, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.24\n",
            "    SM Frequency                                                             cycle/usecond                         496.35\n",
            "    Elapsed Cycles                                                                   cycle                          4,241\n",
            "    Memory [%]                                                                           %                           0.38\n",
            "    DRAM Throughput                                                                      %                           0.07\n",
            "    Duration                                                                       usecond                           8.54\n",
            "    L1/TEX Cache Throughput                                                              %                          20.87\n",
            "    L2 Cache Throughput                                                                  %                           0.34\n",
            "    SM Active Cycles                                                                 cycle                          77.03\n",
            "    Compute (SM) [%]                                                                     %                           0.34\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
            "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                        128\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                           1\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                            Kbyte/block                           1.02\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                            128\n",
            "    Waves Per SM                                                                                                     0.00\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
            "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
            "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
            "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
            "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
            "          description for more details on launch configurations.                                                        \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                             32\n",
            "    Block Limit Shared Mem                                                           block                             32\n",
            "    Block Limit Warps                                                                block                              8\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          12.48\n",
            "    Achieved Active Warps Per SM                                                      warp                           3.99\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
            "          theoretical (100.0%) and measured achieved occupancy (12.5%) can be the result of warp scheduling overheads   \n",
            "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
            "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
            "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "  apply_increment(float *, float *, int), 2022-Aug-30 15:43:50, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.20\n",
            "    SM Frequency                                                             cycle/usecond                         490.80\n",
            "    Elapsed Cycles                                                                   cycle                          4,406\n",
            "    Memory [%]                                                                           %                          25.29\n",
            "    DRAM Throughput                                                                      %                          25.29\n",
            "    Duration                                                                       usecond                           8.96\n",
            "    L1/TEX Cache Throughput                                                              %                          29.36\n",
            "    L2 Cache Throughput                                                                  %                          16.40\n",
            "    SM Active Cycles                                                                 cycle                          2,790\n",
            "    Compute (SM) [%]                                                                     %                          18.63\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
            "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
            "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                        512\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                         256\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                        131,072\n",
            "    Waves Per SM                                                                                                     3.20\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    \n",
            "          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       \n",
            "          occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 16 thread blocks.   \n",
            "          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   \n",
            "          up to 25.0% of the total kernel runtime with a lower occupancy of 21.4%. Try launching a grid with no         \n",
            "          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  \n",
            "          a grid. See the Hardware Model                                                                                \n",
            "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      \n",
            "          details on launch configurations.                                                                             \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              8\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              2\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          78.59\n",
            "    Achieved Active Warps Per SM                                                      warp                          25.15\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
            "          theoretical (100.0%) and measured achieved occupancy (78.6%) can be the result of warp scheduling overheads   \n",
            "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
            "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
            "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dPwTz7r_snVN"
      }
    }
  ]
}